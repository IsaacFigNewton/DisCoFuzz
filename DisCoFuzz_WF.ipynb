{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "anQ2qzh8iFUP",
        "D-B8guUkvWfB",
        "g8cEvh3sqmBn",
        "KSGpL2cdqnJL",
        "LlQjrYegLNE0",
        "E0WdkZgjxgrW",
        "FDhMP2KZIjY2",
        "AoRgIk3niRSn",
        "eNfIsu0YI7H4",
        "JijjtN9qY83_",
        "jNcnHWzsY_QZ",
        "OLTHmgmwxHlA",
        "khVPimP2BHyc"
      ],
      "authorship_tag": "ABX9TyNxeR/S+NzAeM9jJZoRzvwd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IsaacFigNewton/DisCoFuzz/blob/main/DisCoFuzz_WF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import and Config"
      ],
      "metadata": {
        "id": "anQ2qzh8iFUP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download, install dependencies"
      ],
      "metadata": {
        "id": "D-B8guUkvWfB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install POT"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMsYToahwLyr",
        "outputId": "0e92b311-576a-4013-d985-a98c939c7526"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting POT\n",
            "  Downloading pot-0.9.6.post1-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/40.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.2/40.2 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.12/dist-packages (from POT) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6 in /usr/local/lib/python3.12/dist-packages (from POT) (1.16.3)\n",
            "Downloading pot-0.9.6.post1-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: POT\n",
            "Successfully installed POT-0.9.6.post1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import"
      ],
      "metadata": {
        "id": "g8cEvh3sqmBn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nvqg3v1Aheog",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef1c1d05-6ffd-4f27-b067-14d5d273e3f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Error loading framenet-17: Package 'framenet-17' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "from typing import Callable, Dict, List, Tuple, Set\n",
        "import math\n",
        "import numpy as np\n",
        "import random\n",
        "import nltk\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('framenet-17')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.corpus import framenet as fn\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "import spacy\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import scipy.stats as stats\n",
        "from scipy.special import expit, logit\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import ot\n",
        "\n",
        "from sentence_transformers import SentenceTransformer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Config"
      ],
      "metadata": {
        "id": "KSGpL2cdqnJL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = stopwords.words(\"english\")\n",
        "all_synsets = list(wn.all_synsets())"
      ],
      "metadata": {
        "id": "vy5SitxqConQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wn_dict = {\n",
        "    'synset': list(),\n",
        "    'lemmas': list(),\n",
        "    'antonyms': list(),\n",
        "    'gloss': list(),\n",
        "    \"cleaned_gloss\": list(),\n",
        "}\n",
        "\n",
        "for s in all_synsets:\n",
        "  synset_lemma = s.name().split(\".\")[0]\n",
        "  lemmas = s.lemmas()\n",
        "  antonyms = list()\n",
        "  for lemma in lemmas:\n",
        "    antonyms += list(lemma.antonyms())\n",
        "  if len(lemmas) > 1 and len(antonyms) > 0:\n",
        "    wn_dict['synset'].append(s.name())\n",
        "    wn_dict['lemmas'].append([l.name() for l in lemmas if l.name() != synset_lemma])\n",
        "    wn_dict['antonyms'].append([a.name() for a in antonyms])\n",
        "    wn_dict['gloss'].append(s.definition())\n",
        "    cleaned_gloss = \" \".join([t for t in s.definition().split(\" \") if t not in stop_words])\n",
        "    wn_dict['cleaned_gloss'].append(cleaned_gloss.replace(\"_\", \" \"))\n",
        "\n",
        "wn_df = pd.DataFrame.from_dict(wn_dict)\n",
        "wn_df.head()"
      ],
      "metadata": {
        "id": "5f6JWdjeiPkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wn_df = wn_df.sample(frac=0.05).reset_index(drop=True)\n",
        "sample_size = len(wn_df)\n",
        "print(f'Number of synsets: {len(wn_df)}')"
      ],
      "metadata": {
        "id": "hlgrSxXkEBd-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')"
      ],
      "metadata": {
        "id": "vFooUBgRAHBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    print(f\"GPU available: {gpus}\")"
      ],
      "metadata": {
        "id": "k7i_47FWqp85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classes"
      ],
      "metadata": {
        "id": "LlQjrYegLNE0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LemmaVectorizer"
      ],
      "metadata": {
        "id": "E0WdkZgjxgrW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LemmaVectorizer:\n",
        "    def __init__(self, keyed_vectors:dict=None):\n",
        "        self.embedding_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "        self.keyed_vectors = keyed_vectors if keyed_vectors else dict()\n",
        "\n",
        "    def __call__(self, X: str) -> np.ndarray:\n",
        "        v = self.keyed_vectors.get(X)#.lemma_.lower())\n",
        "        if v is not None:\n",
        "            return np.asarray(v, dtype=float)\n",
        "\n",
        "        # if X not in self.keyed_vectors, add it\n",
        "        self.keyed_vectors[X] = self.embedding_model.encode(X)\n",
        "        return self.keyed_vectors[X]"
      ],
      "metadata": {
        "id": "nROyX1iQxi52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FourierPDF\n",
        "for probability density function operations"
      ],
      "metadata": {
        "id": "FDhMP2KZIjY2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FourierPDF:\n",
        "  def __init__(self, kernel_size:int):\n",
        "    self.kernel_size = kernel_size\n",
        "    # get frequencies\n",
        "    self.k_values = tf.cast(\n",
        "        tf.range(0, kernel_size),\n",
        "        tf.complex64\n",
        "    )\n",
        "    # pre-computer partial divisor for faster integration\n",
        "    #   shape=(, self.kernel_size)\n",
        "    # add 1e-20 to avoid division by 0\n",
        "    self.divisor = tf.expand_dims(\n",
        "        self.k_values+1e-20,\n",
        "        axis=0\n",
        "    )\n",
        "\n",
        "  def _get_cdf_batch(self, a: tf.Tensor) -> tf.Tensor:\n",
        "      \"\"\"\n",
        "      Batch integration.\n",
        "      a: shape (batch_size, kernel_size)\n",
        "      Returns: shape (batch_size,)\n",
        "      \"\"\"\n",
        "      if len(tf.shape(a)) != 2:\n",
        "          raise ValueError(f\"Input tensor must have shape (batch_size, kernel_size), received tensor of shape {tf.shape(a)}\")\n",
        "      if a.dtype != tf.complex64:\n",
        "          raise ValueError(f\"Input tensors must be complex64, received {a.dtype}\")\n",
        "\n",
        "      batch_size = tf.shape(a)[0]\n",
        "      # Create indices for the k=0 term for each item in the batch\n",
        "      indices = tf.stack([tf.range(batch_size), tf.zeros(batch_size, dtype=tf.int32)], axis=1)\n",
        "\n",
        "      # get AC term (just set all k=0 values to 0)\n",
        "      AC = tf.tensor_scatter_nd_update(\n",
        "          a,\n",
        "          indices,\n",
        "          tf.zeros(batch_size, dtype=tf.complex64)\n",
        "      )\n",
        "      # get divisors\n",
        "      divisor = tf.broadcast_to(\n",
        "          self.divisor,\n",
        "          [tf.shape(a)[0], self.kernel_size]\n",
        "      )\n",
        "      AC = AC / divisor\n",
        "\n",
        "      # add the k=0 terms back in\n",
        "      return tf.tensor_scatter_nd_update(\n",
        "          AC,\n",
        "          indices,\n",
        "          a[:, 0]\n",
        "      )\n",
        "\n",
        "  def _integrate_batch(self, a: tf.Tensor, ub:float=1, lb:float=0) -> tf.Tensor:\n",
        "      \"\"\"\n",
        "      Batch integration.\n",
        "      a: shape (batch_size, kernel_size)\n",
        "      Returns: shape (batch_size,)\n",
        "      \"\"\"\n",
        "      if len(tf.shape(a)) != 2:\n",
        "          raise ValueError(f\"Input tensor must have shape (batch_size, kernel_size), received tensor of shape {tf.shape(a)}\")\n",
        "      if a.dtype != tf.complex64:\n",
        "          raise ValueError(f\"Input tensors must be complex64, received {a.dtype}\")\n",
        "\n",
        "      batch_size = tf.shape(a)[0]\n",
        "\n",
        "      # Create indices for the k=0 term for each item in the batch\n",
        "      indices = tf.stack([tf.range(batch_size), tf.zeros(batch_size, dtype=tf.int32)], axis=1)\n",
        "\n",
        "      # get AC term (just set all k=0 values to 0)\n",
        "      AC = tf.tensor_scatter_nd_update(\n",
        "          a,\n",
        "          indices,\n",
        "          tf.zeros(batch_size, dtype=tf.complex64)\n",
        "      )\n",
        "      # get divisors\n",
        "      divisor = tf.broadcast_to(\n",
        "          self.divisor,\n",
        "          [tf.shape(a)[0], self.kernel_size],\n",
        "      )\n",
        "\n",
        "      upper_bound = tf.exp(divisor * ub)\n",
        "      lower_bound = tf.exp(divisor * lb)\n",
        "      diff = upper_bound - lower_bound\n",
        "\n",
        "      integrals_k_nonzero = tf.reduce_sum(\n",
        "          (AC / divisor) * diff,\n",
        "          axis=1\n",
        "      )\n",
        "\n",
        "      # Combine k=0 and k>0 terms\n",
        "      return a[:, 0] + integrals_k_nonzero\n",
        "\n",
        "  def _integrate(self, a: tf.Tensor, ub:float=1, lb:float=0) -> tf.Tensor:\n",
        "      \"\"\"\n",
        "      Single integration helper.\n",
        "      a: shape (kernel_size)\n",
        "      Returns: scalar\n",
        "      \"\"\"\n",
        "      if len(tf.shape(a)) != 1:\n",
        "          raise ValueError(f\"Input tensor must have shape (kernel_size,), received tensor of shape {tf.shape(a)}\")\n",
        "      if a.dtype != tf.complex64:\n",
        "          raise ValueError(f\"Input tensors must be complex64, received {a.dtype}\")\n",
        "\n",
        "      a_batch = tf.expand_dims(a, axis=0)\n",
        "      result_batch = self._integrate_batch(a_batch, ub, lb)\n",
        "      return tf.squeeze(result_batch)\n",
        "\n",
        "  def _normalize_batch(self, a: tf.Tensor) -> tf.Tensor:\n",
        "      \"\"\"\n",
        "      Batch normalization of probability density functions.\n",
        "      a: shape (batch_size, kernel_size)\n",
        "      \"\"\"\n",
        "      if len(tf.shape(a)) != 2:\n",
        "          raise ValueError(f\"Input tensor must have shape (batch_size, kernel_size), received tensor of shape {tf.shape(a)}\")\n",
        "      if a.dtype != tf.complex64:\n",
        "          raise ValueError(f\"Input tensor must be complex64, received {a.dtype}\")\n",
        "\n",
        "      total_integral = self._integrate_batch(a)  # (batch_size,)\n",
        "      total_integral = tf.expand_dims(total_integral, 1)  # (batch_size, 1)\n",
        "\n",
        "      # Avoid division by zero\n",
        "      total_integral = tf.where(\n",
        "          tf.abs(total_integral) > 1e-10,\n",
        "          total_integral,\n",
        "          tf.ones_like(total_integral)\n",
        "      )\n",
        "\n",
        "      return a / total_integral\n",
        "\n",
        "  def _normalize(self, a: tf.Tensor) -> tf.Tensor:\n",
        "      \"\"\"\n",
        "      Single normalization helper for normalizing probability density functions.\n",
        "      a: shape (kernel_size,)\n",
        "      Returns: shape (kernel_size,)\n",
        "      \"\"\"\n",
        "      if len(tf.shape(a)) != 1:\n",
        "          raise ValueError(f\"Input tensor must have shape (kernel_size,), received tensor of shape {tf.shape(a)}\")\n",
        "      if a.dtype != tf.complex64:\n",
        "          raise ValueError(f\"Input tensor must be complex64, received {a.dtype}\")\n",
        "\n",
        "      a_batch = tf.expand_dims(a, axis=0)\n",
        "      result_batch = self._normalize_batch(a_batch)\n",
        "      return tf.squeeze(result_batch, axis=0)\n",
        "\n",
        "  def _convolve_batch(self, a: tf.Tensor, b: tf.Tensor) -> tf.Tensor:\n",
        "      \"\"\"\n",
        "      Batch convolution using FFT.\n",
        "      a, b: shape (batch_size, kernel_size)\n",
        "      Returns: shape (batch_size, kernel_size)\n",
        "      \"\"\"\n",
        "      if len(tf.shape(a)) != 2:\n",
        "          raise ValueError(f\"Input tensor must have shape (batch_size, kernel_size), received tensor of shape {tf.shape(a)}\")\n",
        "      if len(tf.shape(b)) != 2:\n",
        "          raise ValueError(f\"Input tensor must have shape (batch_size, kernel_size), received tensor of shape {tf.shape(b)}\")\n",
        "\n",
        "      # Batch FFT convolution\n",
        "      A_fft = tf.signal.fft(tf.cast(a, tf.complex64))\n",
        "      B_fft = tf.signal.fft(tf.cast(b, tf.complex64))\n",
        "      C_fft = A_fft * B_fft\n",
        "      C = tf.signal.ifft(C_fft)\n",
        "\n",
        "      return tf.cast(C, tf.complex64)\n",
        "\n",
        "  def _convolve(self, a: tf.Tensor, b: tf.Tensor) -> tf.Tensor:\n",
        "      \"\"\"\n",
        "      Single convolution helper.\n",
        "      a, b: shape (kernel_size,)\n",
        "      Returns: shape (kernel_size,)\n",
        "      \"\"\"\n",
        "      a_batch = tf.expand_dims(a, axis=0)\n",
        "      b_batch = tf.expand_dims(b, axis=0)\n",
        "      result_batch = self._convolve_batch(a_batch, b_batch)\n",
        "      return tf.squeeze(result_batch, axis=0)\n",
        "\n",
        "  def _differentiate_batch(self, a: tf.Tensor) -> tf.Tensor:\n",
        "      \"\"\"\n",
        "      Batch differentiation.\n",
        "      a: shape (batch_size, kernel_size)\n",
        "      Returns: shape (batch_size, kernel_size)\n",
        "      \"\"\"\n",
        "      if len(tf.shape(a)) != 2:\n",
        "          raise ValueError(f\"Input tensor must have shape (batch_size, kernel_size), received tensor of shape {tf.shape(a)}\")\n",
        "\n",
        "      return a * tf.exp(1j * self.k_values)\n",
        "\n",
        "  def _differentiate(self, a: tf.Tensor) -> tf.Tensor:\n",
        "      \"\"\"\n",
        "      Single differentiation helper.\n",
        "      a: shape (kernel_size,)\n",
        "      Returns: shape (kernel_size,)\n",
        "      \"\"\"\n",
        "      a_batch = tf.expand_dims(a, axis=0)\n",
        "      result_batch = self._differentiate_batch(a_batch)\n",
        "      return tf.squeeze(result_batch, axis=0)"
      ],
      "metadata": {
        "id": "TMyzX1MAGuDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fuzzification Classes"
      ],
      "metadata": {
        "id": "AoRgIk3niRSn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FuzzyFourierSetMixin"
      ],
      "metadata": {
        "id": "eNfIsu0YI7H4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FuzzyFourierSetMixin(FourierPDF):\n",
        "  def __init__(self, sigma: float, kernel_size: int):\n",
        "      if kernel_size < 1:\n",
        "          raise ValueError(\"Kernel size must be at least 1\")\n",
        "      super().__init__(kernel_size)\n",
        "      self.sigma = tf.constant(sigma, dtype=tf.complex64)\n",
        "\n",
        "      # Pre-compute Fourier coefficients for all k values\n",
        "      # C_k = e^{-\\frac{a^{2}k^{2}}{2}} and keep mu portion separate for now\n",
        "      c_k = tf.exp(-0.5 * (self.sigma ** 2) * (self.k_values ** 2))\n",
        "      self.fourier_coeffs = c_k / (2 * np.pi)\n",
        "\n",
        "  def _get_gaussian_at_mu_batch(self, mu: tf.Tensor) -> tf.Tensor:\n",
        "      \"\"\"\n",
        "      Batch computation of Fourier series for Gaussians centered at multiple mu values.\n",
        "      mu: shape (batch_size,)\n",
        "      Returns: shape (batch_size, kernel_size)\n",
        "      \"\"\"\n",
        "      # mu part of C_n = e^{-ikb}\n",
        "      #   combine mu.shape = (batch_size,) with self.k_values.T.shape = (,self.kernel_size)\n",
        "      #   to get tensor of shape (batch_size, self.kernel_size)\n",
        "      mu_c_k = tf.linalg.matmul(\n",
        "          tf.expand_dims(tf.cast(mu, dtype=tf.complex64), axis=1),\n",
        "          tf.expand_dims(self.k_values, axis=0)\n",
        "      )\n",
        "      mu_c_k = tf.exp(-1j * mu_c_k)\n",
        "\n",
        "      # combine (batch_size, self.kernel_size) with (self.kernel_size,) self.fourier_coeffs\n",
        "      return self._normalize_batch(mu_c_k * self.fourier_coeffs)\n",
        "\n",
        "  def fuzzify(self, component: float) -> tf.Tensor:\n",
        "      \"\"\"\n",
        "      Convert a real-valued component to a Fourier series representation of a Gaussian.\n",
        "      component: scalar float\n",
        "      Returns: shape (kernel_size,)\n",
        "      \"\"\"\n",
        "      mu = tf.constant([component], dtype=tf.float32)\n",
        "      return self._fuzzify_batch(mu)\n",
        "\n",
        "  def fuzzify_batch(self, components: tf.Tensor) -> tf.Tensor:\n",
        "      \"\"\"\n",
        "      Batch fuzzification.\n",
        "      components: shape (batch_size,)\n",
        "      Returns: shape (batch_size, kernel_size)\n",
        "      \"\"\"\n",
        "      if len(tf.shape(components)) != 1:\n",
        "          raise ValueError(f\"Input tensor must have shape (batch_size,), received tensor of shape {tf.shape(components)}\")\n",
        "\n",
        "      return self._get_gaussian_at_mu_batch(components)\n",
        "\n",
        "  def negation(self, a: tf.Tensor) -> tf.Tensor:\n",
        "      \"\"\"\n",
        "      Fuzzy negation: NOT(a) = 1 - a\n",
        "      a: shape (kernel_size,)\n",
        "      Returns: shape (kernel_size,)\n",
        "      \"\"\"\n",
        "      # Create representation of constant function 1\n",
        "      one = tf.zeros_like(a)\n",
        "      one = tf.tensor_scatter_nd_update(\n",
        "          one,\n",
        "          [[0]],\n",
        "          [tf.constant(1.0, dtype=tf.complex64)]\n",
        "      )\n",
        "\n",
        "      return self._normalize(one - a)\n",
        "\n",
        "  def negation_batch(self, a: tf.Tensor) -> tf.Tensor:\n",
        "      \"\"\"\n",
        "      Batch fuzzy negation: NOT(a) = 1 - a\n",
        "      a: shape (batch_size, kernel_size)\n",
        "      Returns: shape (batch_size, kernel_size)\n",
        "      \"\"\"\n",
        "      if len(tf.shape(a)) != 2:\n",
        "          raise ValueError(f\"Input tensor must have shape (batch_size, kernel_size), received tensor of shape {tf.shape(a)}\")\n",
        "      batch_size = tf.shape(a)[0]\n",
        "\n",
        "      # Create batch of constant function 1\n",
        "      # base tensor of same shape as a\n",
        "      ones = tf.zeros_like(a)\n",
        "      # indices at which to place 1's\n",
        "      indices = tf.stack([\n",
        "          tf.range(batch_size),\n",
        "          tf.zeros(batch_size, dtype=tf.int32)\n",
        "      ], axis=1)\n",
        "      # ones to be inserted at said indices\n",
        "      updates = tf.ones([batch_size], dtype=tf.complex64)\n",
        "      # update the base tensor with 1's\n",
        "      ones = tf.tensor_scatter_nd_update(ones, indices, updates)\n",
        "\n",
        "      # get normalized negation\n",
        "      return self._normalize_batch(ones - a)\n",
        "\n",
        "  def intersection(self, a: tf.Tensor, b: tf.Tensor, normalize: bool = True) -> tf.Tensor:\n",
        "      \"\"\"\n",
        "      Fuzzy intersection using product (min approximation).\n",
        "      a, b: shape (kernel_size,)\n",
        "      Returns: shape (kernel_size,)\n",
        "      \"\"\"\n",
        "      result = self._convolve(a, b)\n",
        "      if normalize:\n",
        "          result = self._normalize(result)\n",
        "      return result\n",
        "\n",
        "  def intersection_batch(self, a: tf.Tensor, b: tf.Tensor, normalize: bool = True) -> tf.Tensor:\n",
        "      \"\"\"\n",
        "      Batch fuzzy intersection using product.\n",
        "      a, b: shape (batch_size, kernel_size)\n",
        "      Returns: shape (batch_size, kernel_size)\n",
        "      \"\"\"\n",
        "      if len(tf.shape(a)) != 2:\n",
        "          raise ValueError(f\"Input tensor must have shape (batch_size, kernel_size), received tensor of shape {tf.shape(a)}\")\n",
        "      result = self._convolve_batch(a, b)\n",
        "      if normalize:\n",
        "          result = self._normalize_batch(result)\n",
        "      return result\n",
        "\n",
        "  def union(self, a: tf.Tensor, b: tf.Tensor, normalize: bool = True) -> tf.Tensor:\n",
        "      \"\"\"\n",
        "      Fuzzy union: a + b - a*b\n",
        "      a, b: shape (kernel_size,)\n",
        "      Returns: shape (kernel_size,)\n",
        "      \"\"\"\n",
        "      convolved = self._convolve(a, b)\n",
        "      result = a + b - convolved\n",
        "      if normalize:\n",
        "          result = self._normalize(result)\n",
        "      return result\n",
        "\n",
        "  def union_batch(self, a: tf.Tensor, b: tf.Tensor, normalize: bool = True) -> tf.Tensor:\n",
        "      \"\"\"\n",
        "      Batch fuzzy union: a + b - a*b\n",
        "      a, b: shape (batch_size, kernel_size)\n",
        "      Returns: shape (batch_size, kernel_size)\n",
        "      \"\"\"\n",
        "      if len(tf.shape(a)) != 2:\n",
        "          raise ValueError(f\"Input tensor must have shape (batch_size, kernel_size), received tensor of shape {tf.shape(a)}\")\n",
        "      convolved = self._convolve_batch(a, b)\n",
        "      result = a + b - convolved\n",
        "      if normalize:\n",
        "          result = self._normalize_batch(result)\n",
        "      return result"
      ],
      "metadata": {
        "id": "XExOfQ4iI_5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FourierFuzzifier\n",
        "\n",
        "WF geodesic calculation functions based on [the work by Elsa Cazelles, Arnaud Robert, Felipe Tobar](https://github.com/GAMES-UChile/Wasserstein-Fourier.git) in their paper [\"The Wasserstein-Fourier Distance for Stationary Time Series\"](https://arxiv.org/abs/1912.05509) to make it compatible with the component-wise series representation I'm using for gaussians."
      ],
      "metadata": {
        "id": "JijjtN9qY83_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from typing import List, Union\n",
        "import ot\n",
        "\n",
        "class FourierFuzzifier(FuzzyFourierSetMixin):\n",
        "    \"\"\"TensorFlow-accelerated version of FourierFuzzifier with set operations\"\"\"\n",
        "\n",
        "    def __init__(self, sigma: float, kernel_size: int):\n",
        "        if kernel_size < 1:\n",
        "            raise ValueError(\"Kernel size must be at least 1\")\n",
        "        super().__init__(sigma, kernel_size)\n",
        "\n",
        "    def get_npsd_batch(self, a: tf.Tensor) -> tf.Tensor:\n",
        "        # normalize the power spectral densities\n",
        "        if len(tf.shape(a)) != 2:\n",
        "            raise ValueError(f\"Input tensor must have shape (batch_size, kernel_size), received tensor of shape {tf.shape(a)}\")\n",
        "        norms = tf.expand_dims(tf.math.reduce_sum(tf.abs(a), axis=1), axis=1)\n",
        "        norms = tf.broadcast_to(\n",
        "            norms,\n",
        "            [tf.shape(a)[0], tf.shape(a)[1]]\n",
        "        )\n",
        "        return tf.abs(a) / norms\n",
        "\n",
        "    def similarity(self, a: tf.Tensor, b: tf.Tensor, method: str) -> Union[float, np.ndarray]:\n",
        "        \"\"\"\n",
        "        Compute similarity as ot similarity in frequency domain.\n",
        "        a, b: shape (kernel_size,)\n",
        "        Returns: scalar similarity\n",
        "        \"\"\"\n",
        "        if not a or not b:\n",
        "          return None\n",
        "\n",
        "        if len(tf.shape(a)) != 2:\n",
        "            raise ValueError(f\"Input tensor must have shape (batch_size, kernel_size), received tensor of shape {tf.shape(a)}\")\n",
        "        if len(tf.shape(b)) != 2:\n",
        "            raise ValueError(f\"Input tensor must have shape (batch_size, kernel_size), received tensor of shape {tf.shape(b)}\")\n",
        "\n",
        "        return self.similarity_batch(\n",
        "            tf.expand_dims(a, axis=0),\n",
        "            tf.expand_dims(b, axis=0),\n",
        "            method=method\n",
        "        )\n",
        "\n",
        "    def similarity_batch(self, a: tf.Tensor, b: tf.Tensor, method: str) -> Union[float, np.ndarray]:\n",
        "        \"\"\"\n",
        "        Batch computation of pairwise similarities.\n",
        "        a, b: shape (batch_size, kernel_size)\n",
        "        Returns: shape (batch_size,) - similarity for each pair\n",
        "        \"\"\"\n",
        "        if len(tf.shape(a)) != 2:\n",
        "            raise ValueError(f\"Input tensor must have shape (batch_size, kernel_size), received tensor of shape {tf.shape(a)}\")\n",
        "        if len(tf.shape(b)) != 2:\n",
        "            raise ValueError(f\"Input tensor must have shape (batch_size, kernel_size), received tensor of shape {tf.shape(b)}\")\n",
        "\n",
        "        flatten_layer = tf.keras.layers.Flatten()\n",
        "        freqs = tf.range(0, self.kernel_size, dtype=tf.float32)\n",
        "\n",
        "        if method == \"npsd-ot\":\n",
        "            # get normalized power density spectra\n",
        "            a_npsd = self.get_npsd_batch(a)\n",
        "            b_npsd = self.get_npsd_batch(b)\n",
        "\n",
        "            # # energy is proportional to frequency^2 * amplitude^2\n",
        "            # a_energy = a_npsd * a_npsd * freqs * freqs\n",
        "            # b_energy = b_npsd * b_npsd * freqs * freqs\n",
        "            # # Normalize to probability distributions\n",
        "            # a_energy = a_energy / tf.reduce_sum(a_energy, axis=1, keepdims=True)\n",
        "            # b_energy = b_energy / tf.reduce_sum(b_energy, axis=1, keepdims=True)\n",
        "\n",
        "            max_freq = self.kernel_size - 1\n",
        "            a_npsd = a_npsd.numpy()\n",
        "            b_npsd = b_npsd.numpy()\n",
        "\n",
        "            u, v = np.meshgrid(freqs, freqs)\n",
        "            # normalize Wasserstein-2 metric\n",
        "            cost = np.exp(u - v)\n",
        "            # cost = (u - v)**2\n",
        "            cost = np.ascontiguousarray(cost, dtype='float64')\n",
        "\n",
        "            total_cost = 0\n",
        "            for i in range(a.shape[0]):\n",
        "                plan = ot.emd(\n",
        "                    np.ascontiguousarray(a_npsd[i, :]),\n",
        "                    np.ascontiguousarray(b_npsd[i, :]),\n",
        "                    cost,\n",
        "                    check_marginals=False\n",
        "                )\n",
        "                total_cost += np.sum(plan * cost)\n",
        "\n",
        "            return 1-np.log1p(np.abs(total_cost / a.shape[0]))\n",
        "\n",
        "        elif method == \"p-ot\":\n",
        "            # Wasserstein-1 earthmover's distance of probability distributions\n",
        "            #   = integrate(tf.abs(antiderivative(pdf_1) - antiderivative(pdf_2)))\n",
        "            # get cdfs of the distributions\n",
        "            a_cdf = self._get_cdf_batch(a)\n",
        "            b_cdf = self._get_cdf_batch(b)\n",
        "            # get the absolute value of their difference\n",
        "            diff = tf.cast(tf.abs(a_cdf - b_cdf), dtype=tf.complex64)\n",
        "            # integrate their absolute difference\n",
        "            abs_diff = tf.abs(self._integrate_batch(diff))\n",
        "            # print(abs_diff[:5])\n",
        "            return 1-np.log1p(tf.reduce_sum(abs_diff).numpy())\n",
        "\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown method: {method}\")"
      ],
      "metadata": {
        "id": "ry1V5rW9iTIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FuzzyFourierTensorTransformer"
      ],
      "metadata": {
        "id": "jNcnHWzsY_QZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FuzzyFourierTensorTransformer:\n",
        "    \"\"\"\n",
        "    TensorFlow-accelerated fuzzy tensor transformer.\n",
        "    All operations are vectorized and GPU-compatible.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, sigma: float = 0.1, kernel_size: int = 8):\n",
        "        self.fuzzifier = FourierFuzzifier(sigma, kernel_size)\n",
        "        self.kernel_size = kernel_size\n",
        "\n",
        "    @tf.function\n",
        "    def fuzzify(self, A: tf.Tensor) -> tf.Tensor:\n",
        "        \"\"\"\n",
        "        Vectorized fuzzification.\n",
        "        A: (d)\n",
        "        Returns: shape (d, kernel_size)\n",
        "        \"\"\"\n",
        "        if len(tf.shape(A)) != 1:\n",
        "            raise ValueError(f\"Input tensor must have shape (d), received tensor of shape {tf.shape(A)}\")\n",
        "\n",
        "        # Reshape to (batch_size, d, kernel_size)\n",
        "        return self.fuzzifier._get_gaussian_at_mu_batch(A)\n",
        "\n",
        "\n",
        "    @tf.function\n",
        "    def intersection(self, A: tf.Tensor, B: tf.Tensor, normalize: bool = True) -> tf.Tensor:\n",
        "        \"\"\"\n",
        "        Vectorized fuzzy intersection.\n",
        "        A, B: shape (d,kernel_size)\n",
        "        \"\"\"\n",
        "        if not len(A.shape) == 2:\n",
        "          raise ValueError(f\"A must be rank 2 tensors. Expected A.shape == 2, but got A.shape == {A.shape}\")\n",
        "        if not len(B.shape) == 2:\n",
        "          raise ValueError(f\"B must be rank 2 tensors. Expected A.shape == 2, but got A.shape == {B.shape}\")\n",
        "\n",
        "        result = self.fuzzifier._convolve_batch(A, B)\n",
        "\n",
        "        if normalize:\n",
        "            result = self.fuzzifier._normalize_batch(result)\n",
        "\n",
        "        return result\n",
        "\n",
        "\n",
        "    @tf.function\n",
        "    def iterated_intersection(self, vects: tf.Tensor) -> tf.Tensor:\n",
        "        \"\"\"\n",
        "        Efficiently compute intersection over multiple tensors.\n",
        "        vects: shape (n_vects, d,kernel_size)\n",
        "        \"\"\"\n",
        "\n",
        "        # if there's only 1 tensor to get the intersection\n",
        "        if tf.shape(vects)[0] == 1:\n",
        "            return vects[0]\n",
        "\n",
        "        result = vects[0]\n",
        "        for v in vects:\n",
        "          # only include vect in intersection if it's the correct shape\n",
        "          if len(v.shape) == 3:\n",
        "              result = self.intersection(result, v, normalize=False)\n",
        "\n",
        "        # Normalize the final result\n",
        "        return self.fuzzifier._normalize_batch(result)\n",
        "\n",
        "    @tf.function\n",
        "    def union(self, A: tf.Tensor, B: tf.Tensor, normalize: bool = True) -> tf.Tensor:\n",
        "        \"\"\"\n",
        "        Vectorized fuzzy union: A + B - A*B\n",
        "        A, B: shape (d,kernel_size)\n",
        "        \"\"\"\n",
        "        convolved = self.intersection(A, B, normalize=False)\n",
        "        result = A + B - convolved\n",
        "\n",
        "        if normalize:\n",
        "            shape = tf.shape(result)\n",
        "            if len(result.shape) == 3:\n",
        "                result = self.fuzzifier._normalize_batch(result)\n",
        "            else:\n",
        "                result_flat = tf.reshape(result, [-1, self.kernel_size])\n",
        "                result_flat = self.fuzzifier._normalize_batch(result_flat)\n",
        "                result = tf.reshape(result_flat, shape)\n",
        "\n",
        "        return result\n",
        "\n",
        "    @tf.function\n",
        "    def iterated_union(self, vects: tf.Tensor) -> tf.Tensor:\n",
        "        \"\"\"\n",
        "        Efficiently compute union over multiple tensors.\n",
        "        vects: shape (n_vects, d,kernel_size)\n",
        "        \"\"\"\n",
        "\n",
        "        # if there's only 1 tensor to get the union\n",
        "        if tf.shape(vects)[0] == 1:\n",
        "            return vects[0]\n",
        "\n",
        "        result = vects[0]\n",
        "        for v in vects:\n",
        "          # only include vect in union if it's the correct shape\n",
        "          if len(v.shape) == 3:\n",
        "              result = self.union(result, v, normalize=False)\n",
        "\n",
        "        # Normalize the final result\n",
        "        return self.fuzzifier._normalize_batch(result)\n",
        "\n",
        "    def similarity(self, A: tf.Tensor, B: tf.Tensor, method:str = \"p-ot\") -> float:\n",
        "        \"\"\"\n",
        "        Vectorized similarity computation.\n",
        "        A, B: shape (d,kernel_size)\n",
        "        Returns: scalar similarity between the normalized power spectral densities of A, B\n",
        "        \"\"\"\n",
        "        if not len(A.shape) == 2:\n",
        "          raise ValueError(f\"A must be rank 2 tensors. Expected A.shape == 2, but got A.shape == {A.shape}\")\n",
        "        if not len(B.shape) == 2:\n",
        "          raise ValueError(f\"B must be rank 2 tensors. Expected A.shape == 2, but got A.shape == {B.shape}\")\n",
        "\n",
        "        if method == \"cos\":\n",
        "            a_npsd = self.fuzzifier.get_npsd_batch(A)\n",
        "            b_npsd = self.fuzzifier.get_npsd_batch(B)\n",
        "            # numerator = aggregated hadamard product of a_npsd and b_npsd\n",
        "            numerator = tf.reduce_sum(a_npsd * b_npsd)\n",
        "            denominator_a = tf.sqrt(tf.reduce_sum(a_npsd * a_npsd))\n",
        "            denominator_b = tf.sqrt(tf.reduce_sum(b_npsd * b_npsd))\n",
        "            # similarity = correllation coefficient between the two npsd's\n",
        "            similarity = numerator / (denominator_a * denominator_b + 1e-10)\n",
        "            return similarity.numpy()\n",
        "\n",
        "        else:\n",
        "            return self.fuzzifier.similarity_batch(A, B, method)"
      ],
      "metadata": {
        "id": "8-7wCFLUCupJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SpacyDependencyComposer\n",
        "\n",
        "For assigning root of glosses' composition trees:\n",
        "*   if the synset is for a verb, the first verb token is (almost) always the synset referent\n",
        "*   if the synset is for an adverb, the first token after the word \"with\"/\"without\" is (almost) always the synset referent\n",
        "*   if the synset is for an adjective, the first verb or adjective token is (almost) always the synset referent\n",
        "*   if the synset is for a noun, the first noun token is (almost) always the synset referent\n"
      ],
      "metadata": {
        "id": "OLTHmgmwxHlA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "strategies = [\n",
        "      None,\n",
        "      \"mean\",\n",
        "      \"intersection+mean\",\n",
        "      \"intersection+union\",\n",
        "      \"intersection+intersection\",\n",
        "      \"selective_intersection+mean\",\n",
        "      \"selective_intersection+union\",\n",
        "      \"selective_intersection+intersection+mean\",\n",
        "  ]"
      ],
      "metadata": {
        "id": "kcWhlmn0Lnyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SpacyDependencyComposer:\n",
        "  def __init__(self,\n",
        "      strategy:str=None,\n",
        "      spacy_model=None,\n",
        "      lemma_vectorizer=None,\n",
        "      fuzzifier=None\n",
        "    ):\n",
        "    if strategy not in strategies:\n",
        "      raise ValueError(f\"Unknown strategy: {strategy}\")\n",
        "    self.strategy = strategy\n",
        "    self.nlp = spacy.load(\"en_core_web_sm\") if spacy_model is None else spacy_model\n",
        "    self.lemma_vectorizer = LemmaVectorizer() if lemma_vectorizer is None else lemma_vectorizer\n",
        "    self.fuzzifier = FuzzyFourierTensorTransformer() if fuzzifier is None else fuzzifier\n",
        "\n",
        "  def _compose_tok_embedding(self, token) -> tf.Tensor:\n",
        "    # lemma_vectorizer returns a numpy array, so convert it to tf.Tensor for fuzzification\n",
        "    current_tok_tens = self.lemma_vectorizer(token.lemma_.lower())\n",
        "    current_tok_tens = tf.convert_to_tensor(current_tok_tens, dtype=tf.float32)\n",
        "    current_tok_tens = self.fuzzifier.fuzzify(current_tok_tens)\n",
        "\n",
        "    if token.children:\n",
        "      # get all the childrens'embeddings\n",
        "      child_embeddings = [\n",
        "          self._compose_tok_embedding(c)\n",
        "          for c in token.children\n",
        "      ]\n",
        "\n",
        "      if not child_embeddings:\n",
        "        # If no valid children, return the current token's embedding\n",
        "        return current_tok_tens\n",
        "\n",
        "      # compose child embeddings based on strategy\n",
        "      match self.strategy:\n",
        "\n",
        "        case \"mean\":\n",
        "          return tf.reduce_mean(tf.stack(child_embeddings), axis=0)\n",
        "\n",
        "        case \"intersection+mean\":\n",
        "          child_embeddings_intersected = [\n",
        "              self.fuzzifier.intersection(current_tok_tens, c)\n",
        "              for c in child_embeddings\n",
        "          ]\n",
        "          return tf.reduce_mean(tf.stack(child_embeddings_intersected), axis=0)\n",
        "\n",
        "        case \"intersection+union\":\n",
        "          child_embeddings_intersected = [\n",
        "              self.fuzzifier.intersection(current_tok_tens, c)\n",
        "              for c in child_embeddings\n",
        "          ]\n",
        "          return self.fuzzifier.iterated_union(child_embeddings_intersected)\n",
        "\n",
        "        case \"intersection+intersection\":\n",
        "          child_embeddings_intersected = [\n",
        "              self.fuzzifier.intersection(current_tok_tens, c)\n",
        "              for c in child_embeddings\n",
        "          ]\n",
        "          return self.fuzzifier.iterated_intersection(child_embeddings_intersected)\n",
        "\n",
        "        case \"selective_intersection+mean\":\n",
        "          # if the current token is a modifier of some kind, intersect it with all its children\n",
        "          if token.pos_ in {\"VERB\", \"ADJ\", \"ADV\"}:\n",
        "            child_embeddings_intersected = [\n",
        "                self.fuzzifier.intersection(current_tok_tens, c)\n",
        "                for c in child_embeddings\n",
        "            ]\n",
        "            return tf.reduce_mean(tf.stack(child_embeddings_intersected), axis=0)\n",
        "          # otherwise, just return the mean of its children\n",
        "          return tf.reduce_mean(tf.stack(child_embeddings), axis=0)\n",
        "\n",
        "        case \"selective_intersection+union\":\n",
        "          # if the current token is a modifier of some kind, intersect it with all its children\n",
        "          if token.pos_ in {\"VERB\", \"ADJ\", \"ADV\"}:\n",
        "            child_embeddings_intersected = [\n",
        "                self.fuzzifier.intersection(current_tok_tens, c)\n",
        "                for c in child_embeddings\n",
        "            ]\n",
        "            # return the union of these intersected children\n",
        "            return self.fuzzifier.iterated_union(child_embeddings_intersected)\n",
        "          # otherwise, just return the union of its children\n",
        "          return self.fuzzifier.iterated_union(tf.stack(child_embeddings))\n",
        "\n",
        "        case \"selective_intersection+intersection+mean\":\n",
        "          # if the current token is a modifier of some kind, intersect it with all its children\n",
        "          if token.pos_ in {\"VERB\", \"ADJ\", \"ADV\"}:\n",
        "            child_embeddings_intersected = [\n",
        "                self.fuzzifier.intersection(current_tok_tens, c)\n",
        "                for c in child_embeddings\n",
        "            ]\n",
        "            # then intersect those intersections\n",
        "            return self.fuzzifier.iterated_intersection(child_embeddings_intersected)\n",
        "          # otherwise, just return the mean of its children\n",
        "          return tf.reduce_mean(tf.stack(child_embeddings), axis=0)\n",
        "\n",
        "        case _:\n",
        "          raise ValueError(f\"Unknown strategy: {self.strategy}\")\n",
        "\n",
        "    # if the token is a leaf\n",
        "    else:\n",
        "      return current_tok_tens\n",
        "\n",
        "  def __call__(self,\n",
        "      text: str,\n",
        "  ) -> tf.Tensor:\n",
        "      # baseline\n",
        "      if self.strategy is None:\n",
        "          return self.fuzzifier.fuzzify(self.lemma_vectorizer(text))\n",
        "\n",
        "      doc = self.nlp(text)\n",
        "      root_embeddings = []\n",
        "      for sent in doc.sents:\n",
        "          root_emb = self._compose_tok_embedding(sent.root)\n",
        "          if root_emb is not None:\n",
        "            root_embeddings.append(root_emb)\n",
        "\n",
        "      if not root_embeddings:\n",
        "          return None\n",
        "\n",
        "      # get the average\n",
        "      return tf.reduce_mean(tf.stack(root_embeddings), axis=0)"
      ],
      "metadata": {
        "id": "zB_e0jeZxKpe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vectorize and fuzzify wn_df entries"
      ],
      "metadata": {
        "id": "2rzlbteN_ZRB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Config"
      ],
      "metadata": {
        "id": "cqt2mAOA2HsX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorize(strings: List[str]) -> tf.Tensor:\n",
        "  vects = embedding_model.encode(strings)\n",
        "  normalized_vects = (vects - np.min(vects))/(np.max(vects) - np.min(vects))\n",
        "  return tf.convert_to_tensor(normalized_vects)"
      ],
      "metadata": {
        "id": "FXIP6rXdLJ49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spacy_model = spacy.load(\"en_core_web_sm\")\n",
        "lemma_vectorizer = LemmaVectorizer()\n",
        "fuzzifier = FuzzyFourierTensorTransformer()"
      ],
      "metadata": {
        "id": "IhjBULMPDlGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "composers = {\n",
        "    s: SpacyDependencyComposer(\n",
        "        strategy=s,\n",
        "        spacy_model=spacy_model,\n",
        "        lemma_vectorizer=lemma_vectorizer,\n",
        "        fuzzifier=fuzzifier\n",
        "    )\n",
        "    for s in strategies\n",
        "}\n",
        "\n",
        "gloss_vect_fuzzy_cols = {\n",
        "    s: f\"gloss_fuzzy_{s}\"\n",
        "    for s in strategies\n",
        "}"
      ],
      "metadata": {
        "id": "Yj2V-gh8AMvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vectorize, fuzzify"
      ],
      "metadata": {
        "id": "Jyy0WAUjAQfR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get mean embedding for synset lemmas\n",
        "wn_df['synset_vect'] = wn_df['synset'].apply(lambda x: vectorize(x.split(\".\")[0].replace(\"_\", \" \")))\n",
        "wn_df['gloss_vect'] = wn_df['gloss'].apply(vectorize)\n",
        "wn_df['lemmas_vect'] = wn_df['lemmas'].apply(vectorize)"
      ],
      "metadata": {
        "id": "yNcwESzqy-IT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wn_df.head()"
      ],
      "metadata": {
        "id": "nozbqn8W613J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get fuzzified synset embedding\n",
        "wn_df['synset_vect_fuzzy'] = wn_df['synset_vect'].apply(lambda x: fuzzifier.fuzzify(x))\n",
        "# get compositional embeddings for glosses using different strategies\n",
        "for s, composer in composers.items():\n",
        "  print(f\"Getting gloss embedding with {s} approach...\")\n",
        "  wn_df[gloss_vect_fuzzy_cols[s]] = wn_df[\"cleaned_gloss\"].apply(composer)"
      ],
      "metadata": {
        "id": "aqbjTbxL0bt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Columns:\")\n",
        "for c in wn_df.columns:\n",
        "  print(f\"\\t{c}\")"
      ],
      "metadata": {
        "id": "uoXd5mdbF5kr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test fuzzy embedding operators"
      ],
      "metadata": {
        "id": "khVPimP2BHyc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pick a random row in wn_df\n",
        "row_idx = random.choice(wn_df.index)\n",
        "# get the fourier tensors for the first lemma's fuzzy vect\n",
        "fuzzy_vects = wn_df.loc[row_idx, 'synset_vect_fuzzy']\n",
        "intersected_components = fuzzifier.fuzzifier.intersection(fuzzy_vects[0], fuzzy_vects[1])"
      ],
      "metadata": {
        "id": "seUhkIc7qLWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Area under first component of synset {row_idx}: {fuzzifier.fuzzifier._integrate(fuzzy_vects[0])}\")\n",
        "print(f\"Area under second component of synset {row_idx}: {fuzzifier.fuzzifier._integrate(fuzzy_vects[1])}\")\n",
        "print(f\"Area under intersection of first 2 components of synset {row_idx}: {fuzzifier.fuzzifier._integrate(intersected_components)}\")"
      ],
      "metadata": {
        "id": "Iv893EguVTWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate Inner Product (Similarity) Preservation"
      ],
      "metadata": {
        "id": "HaCuGI9oz-EN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Config"
      ],
      "metadata": {
        "id": "Q0eO4NhSEgMu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fuzzifier = FuzzyFourierTensorTransformer()\n",
        "# npsd-ot seems to do best for the fuzzy intersection+mean composition model\n",
        "sim_metric = \"cos\"\n",
        "fuzzifier.fuzzifier.kernel_size"
      ],
      "metadata": {
        "id": "Ei_mdAp1KRMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sim = tf.keras.losses.CosineSimilarity(\n",
        "    axis=-1,\n",
        "    reduction='sum_over_batch_size',\n",
        "    name='cosine_similarity'\n",
        ")\n",
        "def cosine_similarity(a: tf.Tensor, b: tf.Tensor) -> tf.Tensor:\n",
        "  return -1*sim(a, b).numpy()"
      ],
      "metadata": {
        "id": "hO8xAYRTCsMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_pairing_indices = [\n",
        "    tuple(random.sample(range(len(wn_df)), 2))\n",
        "    for i in range(sample_size)\n",
        "]\n",
        "\n",
        "sim_eval_dict = {\n",
        "    \"syn_gloss_cos_sim\": [],\n",
        "    \"is_related\": [],\n",
        "}\n",
        "\n",
        "for s in strategies:\n",
        "  # for comparing inner product of fuzzy synset similarities to related glosses\n",
        "  sim_eval_dict[f\"syn_{gloss_vect_fuzzy_cols[s]}\"] = []"
      ],
      "metadata": {
        "id": "cC6_UQQH0UZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fuzzy space similarities"
      ],
      "metadata": {
        "id": "2rl_b_XBbq6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# extend classes\n",
        "sim_eval_dict[\"is_related\"] = [1, 0] * len(random_pairing_indices)\n",
        "# syn-gloss cosine similarities\n",
        "for a, b in random_pairing_indices:\n",
        "  sim_eval_dict[\"syn_gloss_cos_sim\"].extend([\n",
        "      cosine_similarity(\n",
        "          wn_df.loc[a, 'synset_vect'],\n",
        "          wn_df.loc[a, 'gloss_vect']\n",
        "      ),\n",
        "      cosine_similarity(\n",
        "          wn_df.loc[a, 'synset_vect'],\n",
        "          wn_df.loc[b, 'gloss_vect']\n",
        "      )\n",
        "  ])"
      ],
      "metadata": {
        "id": "f8ekCncuGWEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# syn-gloss custom fuzzy similarities\n",
        "import numpy as np # Ensure numpy is imported for np.nan\n",
        "\n",
        "for s in strategies:\n",
        "  print(f\"Evaluating similarities for gloss embeddings with {s} composition strategy...\")\n",
        "\n",
        "  for a, b in random_pairing_indices:\n",
        "    synset_vect_fuzzy = wn_df.loc[a, 'synset_vect_fuzzy']\n",
        "    fuzzy_col = gloss_vect_fuzzy_cols[s]\n",
        "\n",
        "    gloss_a_fuzzy = wn_df.loc[a, fuzzy_col]\n",
        "    gloss_b_fuzzy = wn_df.loc[b, fuzzy_col]\n",
        "\n",
        "    sim_a = np.nan # Default to NaN\n",
        "    sim_b = np.nan # Default to NaN\n",
        "\n",
        "    # Only calculate similarity if the gloss embedding is not None\n",
        "    if gloss_a_fuzzy is not None:\n",
        "        sim_a = fuzzifier.similarity(\n",
        "            synset_vect_fuzzy,\n",
        "            gloss_a_fuzzy,\n",
        "            sim_metric\n",
        "        )\n",
        "\n",
        "    # Only calculate similarity if the gloss embedding is not None\n",
        "    if gloss_b_fuzzy is not None:\n",
        "        sim_b = fuzzifier.similarity(\n",
        "            synset_vect_fuzzy,\n",
        "            gloss_b_fuzzy,\n",
        "            sim_metric\n",
        "        )\n",
        "\n",
        "    sim_eval_dict[f\"syn_{fuzzy_col}\"].extend([sim_a, sim_b])"
      ],
      "metadata": {
        "id": "Um4V6RVvGDg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sim_eval_df = pd.DataFrame.from_dict(sim_eval_dict)\n",
        "# normalize similarities\n",
        "for col in sim_eval_df.columns:\n",
        "  sim_eval_df[col] = (sim_eval_df[col] - sim_eval_df[col].min()) / (sim_eval_df[col].max() - sim_eval_df[col].min())\n",
        "sim_eval_df.head()"
      ],
      "metadata": {
        "id": "sY2YQfZdAHNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sim_eval_df.describe()"
      ],
      "metadata": {
        "id": "B2lubAtktuJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for c in sim_eval_df.columns:\n",
        "  print(f\"Number of np.nans: {np.sum(sim_eval_df[c].isna())}\")"
      ],
      "metadata": {
        "id": "1r6XCmtmt623"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize embedding similarities"
      ],
      "metadata": {
        "id": "YH5lwyz65uXb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cmap = plt.get_cmap(\"viridis\")\n",
        "colors = cmap(np.linspace(0, 1, len(sim_eval_df.columns)))\n",
        "for i, col in enumerate(sim_eval_df.columns):\n",
        "  if col in [\"syn_gloss_cos_sim\", \"is_related\"]:\n",
        "    continue\n",
        "  plt.scatter(\n",
        "      x=sim_eval_df[\"syn_gloss_cos_sim\"],\n",
        "      y=sim_eval_df[col],\n",
        "      color=colors[i],\n",
        "      label=col\n",
        "  )\n",
        "\n",
        "plt.xlabel(\"synset-gloss cosine imilarity (sentence transformer)\")\n",
        "plt.ylabel(\"fuzzy synset-gloss similarity (compositional)\")\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.yscale(\"log\")\n",
        "plt.title(\"synset-gloss Fuzzy Similarity vs. synset-gloss Fuzzy Compositional Similarity\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "z2kDWWey7hl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sim_eval_df.columns"
      ],
      "metadata": {
        "id": "HsP20swxEVUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(16, 8))\n",
        "\n",
        "plt.title(f\"Confusion Matrices for different embedding composition methods using {sim_metric} similarity\\n\")\n",
        "for i, col in enumerate(sim_eval_df.columns):\n",
        "    if col in [\"is_related\"]:\n",
        "      continue\n",
        "\n",
        "    # Calculate confusion matrix\n",
        "    cm = confusion_matrix(\n",
        "        sim_eval_df['is_related'],\n",
        "         (sim_eval_df[col] >= sim_eval_df[col].mean()).astype(int)\n",
        "    )\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    plt.subplot(4, 3, i+1)\n",
        "    sns.heatmap(\n",
        "        cm,\n",
        "        annot=True,\n",
        "        fmt='d',\n",
        "        cmap='viridis',\n",
        "        xticklabels=['Unrelated (0)', 'Related (1)'],\n",
        "        yticklabels=['Unrelated (0)', 'Related (1)']\n",
        "    )\n",
        "    plt.title(f'Confusion Matrix for {col.replace(\"syn_gloss_\", \"\").replace(\"_\", \" \")}')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qyA3bAz5rVTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stat analysis"
      ],
      "metadata": {
        "id": "nnYJg_5KB0aA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Correlation coefficients"
      ],
      "metadata": {
        "id": "zG9mgV0M3PX_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "ax = sns.heatmap(sim_eval_df.corr(), annot=True)\n",
        "ax.tick_params(axis='x', labelrotation=30)\n",
        "plt.title(f\"Correlation coefficients between compositional models' similarity estimates for the {sim_metric} metric\\n\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dxwRszRk-MQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparing composition strategies' differentiation capability between related and unrelated glosses"
      ],
      "metadata": {
        "id": "rzk0-3w0a72s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sep_eval_dict = {\n",
        "    \"mean_cos_similarity\": [],\n",
        "    \"cos_separability\": []\n",
        "}\n",
        "for s in strategies:\n",
        "  sep_eval_dict[f\"separability_{s}\"] = []"
      ],
      "metadata": {
        "id": "6OBSfVu_DWRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, len(sim_eval_df), 2):\n",
        "  # cosine similarity\n",
        "  sep_eval_dict[\"mean_cos_similarity\"].append(sim_eval_df.loc[i, \"syn_gloss_cos_sim\"]/2 + sim_eval_df.loc[i+1, \"syn_gloss_cos_sim\"]/2)\n",
        "  sep_eval_dict[\"cos_separability\"].append(sim_eval_df.loc[i, \"syn_gloss_cos_sim\"] - sim_eval_df.loc[i+1, \"syn_gloss_cos_sim\"])\n",
        "  for s in strategies:\n",
        "    strat = f\"syn_{gloss_vect_fuzzy_cols[s]}\"\n",
        "    sep_eval_dict[f\"separability_{s}\"] = sim_eval_df.loc[i, strat] - sim_eval_df.loc[i+1, strat]\n",
        "\n",
        "sep_eval_df = pd.DataFrame.from_dict(sep_eval_dict)"
      ],
      "metadata": {
        "id": "Iii0LuMda-oX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visuals"
      ],
      "metadata": {
        "id": "Nrb2rLlIyhhK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for c in sep_eval_df.columns:\n",
        "  if c in [\"mean_cos_similarity\"]:\n",
        "    continue\n",
        "  plt.scatter(\n",
        "      x=sep_eval_df[\"mean_cos_similarity\"],\n",
        "      y=sep_eval_df[c],\n",
        "      label=c\n",
        "  )\n",
        "plt.xlabel(\"Mean cosine similarity\")\n",
        "plt.ylabel(\"Similarity difference\")\n",
        "# plt.xscale(\"log\")\n",
        "plt.yscale(\"log\")\n",
        "plt.legend(\n",
        "    [c for c in sep_eval_df.columns if c not in [\"mean_cos_similarity\"]],\n",
        "    bbox_to_anchor=(1.05, 1),\n",
        "    loc='upper left'\n",
        ")\n",
        "plt.title(f\"Similarity difference of different embedding composition methods for the {sim_metric} metric\\n\")\n",
        "plt.show()\n",
        "\n",
        "del sep_eval_df[\"mean_cos_similarity\"]"
      ],
      "metadata": {
        "id": "bFFmJxyou7gP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in sep_eval_df.columns:\n",
        "  plt.hist(\n",
        "      sep_eval_df[col],\n",
        "      bins=100,\n",
        "      alpha=0.8,\n",
        "      # range=(-.01, .01)\n",
        "  )\n",
        "\n",
        "plt.xlabel(\"Similarity difference\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "# plt.xscale(\"log\")\n",
        "plt.yscale(\"log\")\n",
        "plt.legend(\n",
        "    sep_eval_df.columns,\n",
        "    bbox_to_anchor=(1.05, 1),\n",
        "    loc='upper left'\n",
        ")\n",
        "plt.title(f\"Similarity difference of different embedding composition methods with {sim_metric} similarity\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lwiE07vcD9LF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Significance tests for separability"
      ],
      "metadata": {
        "id": "xX3UcF5vybeM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"p-value for separability of...\")\n",
        "for col in sep_eval_df.columns:\n",
        "  # get probability mean(eval_df[\"separability_fuzzy\"]) > 0\n",
        "  p = stats.ttest_1samp(\n",
        "      sep_eval_df[col],\n",
        "      0,\n",
        "      alternative=\"greater\"\n",
        "  ).pvalue\n",
        "  print(f\"\\t{col} > 0:{'\\t'*(10 - len(col)//7)}{p}\")"
      ],
      "metadata": {
        "id": "0gCmGKvJbpTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Yo69TsC0brnP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}