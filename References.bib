@article{DBLP:journals/corr/abs-2108-12409,
  author       = {Ofir Press and
                  Noah A. Smith and
                  Mike Lewis},
  title        = {Train Short, Test Long: Attention with Linear Biases Enables Input
                  Length Extrapolation},
  journal      = {CoRR},
  volume       = {abs/2108.12409},
  year         = {2021},
  url          = {https://arxiv.org/abs/2108.12409},
  eprinttype    = {arXiv},
  eprint       = {2108.12409},
  timestamp    = {Thu, 02 Sep 2021 14:42:29 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2108-12409.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@misc{tai2015improvedsemanticrepresentationstreestructured,
      title={Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks}, 
      author={Kai Sheng Tai and Richard Socher and Christopher D. Manning},
      year={2015},
      eprint={1503.00075},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1503.00075}, 
}
@inproceedings{socher-etal-2013-recursive,
    title = "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank",
    author = "Socher, Richard  and
      Perelygin, Alex  and
      Wu, Jean  and
      Chuang, Jason  and
      Manning, Christopher D.  and
      Ng, Andrew  and
      Potts, Christopher",
    editor = "Yarowsky, David  and
      Baldwin, Timothy  and
      Korhonen, Anna  and
      Livescu, Karen  and
      Bethard, Steven",
    booktitle = "Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing",
    month = oct,
    year = "2013",
    address = "Seattle, Washington, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D13-1170/",
    pages = "1631--1642"
}
@article{GangemiEtAl2017,
  author = {Gangemi, Aldo and Presutti, Valentina and Recupero, Diego Reforgiato and Nuzzolese, Andrea Giovanni and Draicchio, Francesco and MongiovÃ¬, Misael},
  journal = {Semantic Web},
  number = 6,
  pages = {873-893},
  title = {{Semantic Web Machine Reading with FRED}},
  volume = 8,
  year = 2017
}
@inproceedings{10.1007/978-3-031-94578-6_4,
author = {Gangemi, Aldo and Graciotti, Arianna and Meloni, Antonello and Nuzzolese, Andrea G. and Presutti, Valentina and Reforgiato Recupero, Diego and Russo, Alessandro},
title = {py-amr2fred: A Python Library for&nbsp;Converting Text into OWL-Compliant RDF KGs},
year = {2025},
isbn = {978-3-031-94577-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-94578-6_4},
doi = {10.1007/978-3-031-94578-6_4},
abstract = {This paper introduces py-amr2fred, a Python library that converts natural language text into OWL-compliant RDF Knowledge Graphs (KGs) through an advanced pipeline integrating Large Language Models, Abstract Meaning Representation (AMR) parsing and semantic enrichment. Designed for scalability and flexibility, the library addresses limitations in existing solutions and facilitates seamless integration into diverse applications. To demonstrate its effectiveness, we present MusicBO, a domain-specific KG capturing the historical, cultural, and relational aspects of musical heritage. Constructed from a multilingual corpus, MusicBO leverages the pipeline’s capabilities for text processing, AMR parsing, RDF transformation, and quality assurance via back-translation validation. The resulting graph, comprising over 531,000 triples, is publicly accessible and serves as a resource for education, research, and digital storytelling in cultural heritage. Additionally, we propose an intrinsic evaluation method for the quality assessment of the generated KGs, leveraging Open Knowledge Extraction motifs. A manually curated benchmark dataset complements this evaluation framework, providing a valuable resource for future research in text-to-KG construction. The contributions of this work underscore the potential of py-amr2fred in advancing automated, scalable, and domain-independent KG generation.},
booktitle = {The Semantic Web: 22nd European Semantic Web Conference, ESWC 2025, Portoroz, Slovenia, June 1–5, 2025, Proceedings, Part II},
pages = {65–83},
numpages = {19},
keywords = {KG construction, Text-to-RDF transformation, Abstract Meaning Representation, LLMs, Semantic web technologies, Provenance-aware RDF},
location = {Portoroz, Slovenia}
}
@misc{hu2025graggraphretrievalaugmentedgeneration,
      title={GRAG: Graph Retrieval-Augmented Generation}, 
      author={Yuntong Hu and Zhihan Lei and Zheng Zhang and Bo Pan and Chen Ling and Liang Zhao},
      year={2025},
      eprint={2405.16506},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2405.16506}, 
}
@inproceedings{mao-etal-2021-alignment,
    title = "From Alignment to Assignment: Frustratingly Simple Unsupervised Entity Alignment",
    author = "Mao, Xin  and
      Wang, Wenting  and
      Wu, Yuanbin  and
      Lan, Man",
    editor = "Moens, Marie-Francine  and
      Huang, Xuanjing  and
      Specia, Lucia  and
      Yih, Scott Wen-tau",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.226/",
    doi = "10.18653/v1/2021.emnlp-main.226",
    pages = "2843--2853",
    abstract = "Cross-lingual entity alignment (EA) aims to find the equivalent entities between crosslingual KGs (Knowledge Graphs), which is a crucial step for integrating KGs. Recently, many GNN-based EA methods are proposed and show decent performance improvements on several public datasets. However, existing GNN-based EA methods inevitably inherit poor interpretability and low efficiency from neural networks. Motivated by the isomorphic assumption of GNN-based methods, we successfully transform the cross-lingual EA problem into an assignment problem. Based on this re-definition, we propose a frustratingly Simple but Effective Unsupervised entity alignment method (SEU) without neural networks. Extensive experiments have been conducted to show that our proposed unsupervised approach even beats advanced supervised methods across all public datasets while having high efficiency, interpretability, and stability."
}
@misc{tull2024compositionalinterpretabilityxai,
      title={Towards Compositional Interpretability for XAI}, 
      author={Sean Tull and Robin Lorenz and Stephen Clark and Ilyas Khan and Bob Coecke},
      year={2024},
      eprint={2406.17583},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2406.17583}, 
}
@book{Wittgenstein1953-WITPI-4,
	address = {New York, NY, USA},
	author = {Ludwig Wittgenstein},
	editor = {G. E. M. Anscombe},
	publisher = {Wiley-Blackwell},
	title = {Philosophical Investigations},
	year = {1953}
}
@article{Senel_2018,
   title={Semantic Structure and Interpretability of Word Embeddings},
   volume={26},
   ISSN={2329-9304},
   url={http://dx.doi.org/10.1109/TASLP.2018.2837384},
   DOI={10.1109/taslp.2018.2837384},
   number={10},
   journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
   publisher={Institute of Electrical and Electronics Engineers (IEEE)},
   author={Senel, Lutfi Kerem and Utlu, Ihsan and Yucesoy, Veysel and Koc, Aykut and Cukur, Tolga},
   year={2018},
   month=oct, pages={1769–1779} }
@misc{mikolov2013efficientestimationwordrepresentations,
      title={Efficient Estimation of Word Representations in Vector Space}, 
      author={Tomas Mikolov and Kai Chen and Greg Corrado and Jeffrey Dean},
      year={2013},
      eprint={1301.3781},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1301.3781}, 
}
@article{10.1162/coli.2006.32.1.13,
    author = {Budanitsky, Alexander and Hirst, Graeme},
    title = {Evaluating WordNet-based Measures of Lexical Semantic Relatedness},
    journal = {Computational Linguistics},
    volume = {32},
    number = {1},
    pages = {13-47},
    year = {2006},
    month = {03},
    abstract = {The quantification of lexical semantic relatedness has many applications in NLP, and many different measures have been proposed. We evaluate five of these measures, all of which use WordNet as their central resource, by comparing their performance in detecting and correcting real-word spelling errors. An information-content-based measure proposed by Jiang and Conrath is found superior to those proposed by Hirst and St-Onge, Leacock and Chodorow, Lin, and Resnik. In addition, we explain why distributional similarity is not an adequate proxy for lexical semantic relatedness.},
    issn = {0891-2017},
    doi = {10.1162/coli.2006.32.1.13},
    url = {https://doi.org/10.1162/coli.2006.32.1.13},
    eprint = {https://direct.mit.edu/coli/article-pdf/32/1/13/1798246/coli.2006.32.1.13.pdf},
}
@misc{zhou2024trustworthinessretrievalaugmentedgenerationsystems,
      title={Trustworthiness in Retrieval-Augmented Generation Systems: A Survey}, 
      author={Yujia Zhou and Yan Liu and Xiaoxi Li and Jiajie Jin and Hongjin Qian and Zheng Liu and Chaozhuo Li and Zhicheng Dou and Tsung-Yi Ho and Philip S. Yu},
      year={2024},
      eprint={2409.10102},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2409.10102}, 
}
@misc{eisinger2025quantummethodsmanagingambiguity,
      title={Quantum Methods for Managing Ambiguity in Natural Language Processing}, 
      author={Jurek Eisinger and Ward Gauderis and Lin de Huybrecht and Geraint A. Wiggins},
      year={2025},
      eprint={2504.00040},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2504.00040}, 
}
@INPROCEEDINGS {9996813,
        author = { Alexander, Aaranya and Widdows, Dominic },
        booktitle = { 2022 IEEE/ACM 7th Symposium on Edge Computing (SEC) },
        title = {{ Quantum Text Encoding for Classification Tasks }},
        year = {2022},
        volume = {},
        ISSN = {},
        pages = {355-361},
        abstract = { This paper explores text classification on quantum computers. Previous results have achieved perfect accuracy on an artificial dataset of 100 short sentences, but at the unscalable cost of using a qubit for each word. This paper demonstrates that an amplitude encoded feature map combined with a quantum support vector machine can achieve 62% average accuracy predicting sentiment using a dataset of 50 actual movie reviews. This is still small, but considerably larger than previously-reported results in quantum NLP. },
        keywords = {Support vector machines;Computers;Costs;Text categorization;Qubit;Motion pictures;Encoding},
        doi = {10.1109/SEC54971.2022.00052},
        url = {https://doi.ieeecomputersociety.org/10.1109/SEC54971.2022.00052},
        publisher = {IEEE Computer Society},
        address = {Los Alamitos, CA, USA},
        month =Dec
}
@misc{zhurov2025fuzzyontologyembeddingsvisual,
      title={Fuzzy Ontology Embeddings and Visual Query Building for Ontology Exploration}, 
      author={Vladimir Zhurov and John Kausch and Kamran Sedig and Mostafa Milani},
      year={2025},
      eprint={2508.08128},
      archivePrefix={arXiv},
      primaryClass={cs.HC},
      url={https://arxiv.org/abs/2508.08128}, 
}
@article{ZADEH1965338,
    title = {Fuzzy sets},
    journal = {Information and Control},
    volume = {8},
    number = {3},
    pages = {338-353},
    year = {1965},
    issn = {0019-9958},
    doi = {https://doi.org/10.1016/S0019-9958(65)90241-X},
    url = {https://www.sciencedirect.com/science/article/pii/S001999586590241X},
    author = {L.A. Zadeh},
    abstract = {A fuzzy set is a class of objects with a continuum of grades of membership. Such a set is characterized by a membership (characteristic) function which assigns to each object a grade of membership ranging between zero and one. The notions of inclusion, union, intersection, complement, relation, convexity, etc., are extended to such sets, and various properties of these notions in the context of fuzzy sets are established. In particular, a separation theorem for convex fuzzy sets is proved without requiring that the fuzzy sets be disjoint.}
}
@article{article,
    author = {Okal, Benard and Miruka, Frida},
    year = {2016},
    month = {06},
    pages = {62-72},
    title = {Application of Set Theory Formulas in the Presentation of Lexical Meronymy},
    volume = {1},
    journal = {Saudi Journal of Humanities and Social Sciences},
    doi = {10.21276/sjhss.2016.1.2.5}
}
@misc{https://doi.org/10.5281/zenodo.17154580,
  doi = {10.5281/ZENODO.17154580},
  url = {https://zenodo.org/doi/10.5281/zenodo.17154580},
  author = {Fabiano, Nicola},
  title = {Quantum Metric Spaces: Replacing Fuzzy Metrics with the Hilbert Space  Structure of Quantum States},
  publisher = {Zenodo},
  year = {2025},
  copyright = {Creative Commons Attribution 4.0 International}
}
@article{DBLP:journals/corr/abs-1003-4394,
  author       = {Bob Coecke and
                  Mehrnoosh Sadrzadeh and
                  Stephen Clark},
  title        = {Mathematical Foundations for a Compositional Distributional Model
                  of Meaning},
  journal      = {CoRR},
  volume       = {abs/1003.4394},
  year         = {2010},
  url          = {http://arxiv.org/abs/1003.4394},
  eprinttype    = {arXiv},
  eprint       = {1003.4394},
  timestamp    = {Mon, 13 Aug 2018 16:46:35 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1003-4394.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{10.5555/3045118.3045221,
author = {Kusner, Matt J. and Sun, Yu and Kolkin, Nicholas I. and Weinberger, Kilian Q.},
title = {From word embeddings to document distances},
year = {2015},
publisher = {JMLR.org},
abstract = {We present the Word Mover's Distance (WMD), a novel distance function between text documents. Our work is based on recent results in word embeddings that learn semantically meaningful representations for words from local cooccurrences in sentences. The WMD distance measures the dissimilarity between two text documents as the minimum amount of distance that the embedded words of one document need to "travel" to reach the embedded words of another document. We show that this distance metric can be cast as an instance of the Earth Mover's Distance, a well studied transportation problem for which several highly efficient solvers have been developed. Our metric has no hyperparameters and is straight-forward to implement. Further, we demonstrate on eight real world document classification data sets, in comparison with seven state-of-the-art baselines, that the WMD metric leads to unprecedented low k-nearest neighbor document classification error rates.},
booktitle = {Proceedings of the 32nd International Conference on International Conference on Machine Learning - Volume 37},
pages = {957–966},
numpages = {10},
location = {Lille, France},
series = {ICML'15}
}