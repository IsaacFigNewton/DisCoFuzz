@article{DBLP:journals/corr/abs-2108-12409,
  author       = {Ofir Press and
                  Noah A. Smith and
                  Mike Lewis},
  title        = {Train Short, Test Long: Attention with Linear Biases Enables Input
                  Length Extrapolation},
  journal      = {CoRR},
  volume       = {abs/2108.12409},
  year         = {2021},
  url          = {https://arxiv.org/abs/2108.12409},
  eprinttype    = {arXiv},
  eprint       = {2108.12409},
  timestamp    = {Thu, 02 Sep 2021 14:42:29 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2108-12409.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@misc{tai2015improvedsemanticrepresentationstreestructured,
      title={Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks}, 
      author={Kai Sheng Tai and Richard Socher and Christopher D. Manning},
      year={2015},
      eprint={1503.00075},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1503.00075}, 
}
@inproceedings{socher-etal-2013-recursive,
    title = "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank",
    author = "Socher, Richard  and
      Perelygin, Alex  and
      Wu, Jean  and
      Chuang, Jason  and
      Manning, Christopher D.  and
      Ng, Andrew  and
      Potts, Christopher",
    editor = "Yarowsky, David  and
      Baldwin, Timothy  and
      Korhonen, Anna  and
      Livescu, Karen  and
      Bethard, Steven",
    booktitle = "Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing",
    month = oct,
    year = "2013",
    address = "Seattle, Washington, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D13-1170/",
    pages = "1631--1642"
}
@article{GangemiEtAl2017,
  author = {Gangemi, Aldo and Presutti, Valentina and Recupero, Diego Reforgiato and Nuzzolese, Andrea Giovanni and Draicchio, Francesco and MongiovÃ¬, Misael},
  journal = {Semantic Web},
  number = 6,
  pages = {873-893},
  title = {{Semantic Web Machine Reading with FRED}},
  volume = 8,
  year = 2017
}
@inproceedings{10.1007/978-3-031-94578-6_4,
author = {Gangemi, Aldo and Graciotti, Arianna and Meloni, Antonello and Nuzzolese, Andrea G. and Presutti, Valentina and Reforgiato Recupero, Diego and Russo, Alessandro},
title = {py-amr2fred: A Python Library for&nbsp;Converting Text into OWL-Compliant RDF KGs},
year = {2025},
isbn = {978-3-031-94577-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-94578-6_4},
doi = {10.1007/978-3-031-94578-6_4},
abstract = {This paper introduces py-amr2fred, a Python library that converts natural language text into OWL-compliant RDF Knowledge Graphs (KGs) through an advanced pipeline integrating Large Language Models, Abstract Meaning Representation (AMR) parsing and semantic enrichment. Designed for scalability and flexibility, the library addresses limitations in existing solutions and facilitates seamless integration into diverse applications. To demonstrate its effectiveness, we present MusicBO, a domain-specific KG capturing the historical, cultural, and relational aspects of musical heritage. Constructed from a multilingual corpus, MusicBO leverages the pipeline’s capabilities for text processing, AMR parsing, RDF transformation, and quality assurance via back-translation validation. The resulting graph, comprising over 531,000 triples, is publicly accessible and serves as a resource for education, research, and digital storytelling in cultural heritage. Additionally, we propose an intrinsic evaluation method for the quality assessment of the generated KGs, leveraging Open Knowledge Extraction motifs. A manually curated benchmark dataset complements this evaluation framework, providing a valuable resource for future research in text-to-KG construction. The contributions of this work underscore the potential of py-amr2fred in advancing automated, scalable, and domain-independent KG generation.},
booktitle = {The Semantic Web: 22nd European Semantic Web Conference, ESWC 2025, Portoroz, Slovenia, June 1–5, 2025, Proceedings, Part II},
pages = {65–83},
numpages = {19},
keywords = {KG construction, Text-to-RDF transformation, Abstract Meaning Representation, LLMs, Semantic web technologies, Provenance-aware RDF},
location = {Portoroz, Slovenia}
}
@misc{hu2025graggraphretrievalaugmentedgeneration,
      title={GRAG: Graph Retrieval-Augmented Generation}, 
      author={Yuntong Hu and Zhihan Lei and Zheng Zhang and Bo Pan and Chen Ling and Liang Zhao},
      year={2025},
      eprint={2405.16506},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2405.16506}, 
}
@inproceedings{mao-etal-2021-alignment,
    title = "From Alignment to Assignment: Frustratingly Simple Unsupervised Entity Alignment",
    author = "Mao, Xin  and
      Wang, Wenting  and
      Wu, Yuanbin  and
      Lan, Man",
    editor = "Moens, Marie-Francine  and
      Huang, Xuanjing  and
      Specia, Lucia  and
      Yih, Scott Wen-tau",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.226/",
    doi = "10.18653/v1/2021.emnlp-main.226",
    pages = "2843--2853",
    abstract = "Cross-lingual entity alignment (EA) aims to find the equivalent entities between crosslingual KGs (Knowledge Graphs), which is a crucial step for integrating KGs. Recently, many GNN-based EA methods are proposed and show decent performance improvements on several public datasets. However, existing GNN-based EA methods inevitably inherit poor interpretability and low efficiency from neural networks. Motivated by the isomorphic assumption of GNN-based methods, we successfully transform the cross-lingual EA problem into an assignment problem. Based on this re-definition, we propose a frustratingly Simple but Effective Unsupervised entity alignment method (SEU) without neural networks. Extensive experiments have been conducted to show that our proposed unsupervised approach even beats advanced supervised methods across all public datasets while having high efficiency, interpretability, and stability."
}
@misc{tull2024compositionalinterpretabilityxai,
      title={Towards Compositional Interpretability for XAI}, 
      author={Sean Tull and Robin Lorenz and Stephen Clark and Ilyas Khan and Bob Coecke},
      year={2024},
      eprint={2406.17583},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2406.17583}, 
}
@book{Wittgenstein1953-WITPI-4,
	address = {New York, NY, USA},
	author = {Ludwig Wittgenstein},
	editor = {G. E. M. Anscombe},
	publisher = {Wiley-Blackwell},
	title = {Philosophical Investigations},
	year = {1953}
}
@article{Senel_2018,
   title={Semantic Structure and Interpretability of Word Embeddings},
   volume={26},
   ISSN={2329-9304},
   url={http://dx.doi.org/10.1109/TASLP.2018.2837384},
   DOI={10.1109/taslp.2018.2837384},
   number={10},
   journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
   publisher={Institute of Electrical and Electronics Engineers (IEEE)},
   author={Senel, Lutfi Kerem and Utlu, Ihsan and Yucesoy, Veysel and Koc, Aykut and Cukur, Tolga},
   year={2018},
   month=oct, pages={1769–1779} }
@misc{mikolov2013efficientestimationwordrepresentations,
      title={Efficient Estimation of Word Representations in Vector Space}, 
      author={Tomas Mikolov and Kai Chen and Greg Corrado and Jeffrey Dean},
      year={2013},
      eprint={1301.3781},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1301.3781}, 
}
@article{10.1162/coli.2006.32.1.13,
    author = {Budanitsky, Alexander and Hirst, Graeme},
    title = {Evaluating WordNet-based Measures of Lexical Semantic Relatedness},
    journal = {Computational Linguistics},
    volume = {32},
    number = {1},
    pages = {13-47},
    year = {2006},
    month = {03},
    abstract = {The quantification of lexical semantic relatedness has many applications in NLP, and many different measures have been proposed. We evaluate five of these measures, all of which use WordNet as their central resource, by comparing their performance in detecting and correcting real-word spelling errors. An information-content-based measure proposed by Jiang and Conrath is found superior to those proposed by Hirst and St-Onge, Leacock and Chodorow, Lin, and Resnik. In addition, we explain why distributional similarity is not an adequate proxy for lexical semantic relatedness.},
    issn = {0891-2017},
    doi = {10.1162/coli.2006.32.1.13},
    url = {https://doi.org/10.1162/coli.2006.32.1.13},
    eprint = {https://direct.mit.edu/coli/article-pdf/32/1/13/1798246/coli.2006.32.1.13.pdf},
}
@misc{zhou2024trustworthinessretrievalaugmentedgenerationsystems,
      title={Trustworthiness in Retrieval-Augmented Generation Systems: A Survey}, 
      author={Yujia Zhou and Yan Liu and Xiaoxi Li and Jiajie Jin and Hongjin Qian and Zheng Liu and Chaozhuo Li and Zhicheng Dou and Tsung-Yi Ho and Philip S. Yu},
      year={2024},
      eprint={2409.10102},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2409.10102}, 
}
@inproceedings{liu-etal-2018-discourse,
    title = "Discourse Representation Structure Parsing",
    author = "Liu, Jiangming  and
      Cohen, Shay B.  and
      Lapata, Mirella",
    editor = "Gurevych, Iryna  and
      Miyao, Yusuke",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P18-1040/",
    doi = "10.18653/v1/P18-1040",
    pages = "429--439",
    abstract = "We introduce an open-domain neural semantic parser which generates formal meaning representations in the style of Discourse Representation Theory (DRT; Kamp and Reyle 1993). We propose a method which transforms Discourse Representation Structures (DRSs) to trees and develop a structure-aware model which decomposes the decoding process into three stages: basic DRS structure prediction, condition prediction (i.e., predicates and relations), and referent prediction (i.e., variables). Experimental results on the Groningen Meaning Bank (GMB) show that our model outperforms competitive baselines by a wide margin."
}
@inproceedings{kartsaklis-etal-2012-unified,
    title = "A Unified Sentence Space for Categorical Distributional-Compositional Semantics: Theory and Experiments",
    author = "Kartsaklis, Dimitri  and
      Sadrzadeh, Mehrnoosh  and
      Pulman, Stephen",
    editor = "Kay, Martin  and
      Boitet, Christian",
    booktitle = "Proceedings of {COLING} 2012: Posters",
    month = dec,
    year = "2012",
    address = "Mumbai, India",
    publisher = "The COLING 2012 Organizing Committee",
    url = "https://aclanthology.org/C12-2054/",
    pages = "549--558"
}
@misc{scrucca2025modelbasedclusteringapproachbounded,
      title={A Model-Based Clustering Approach for Bounded Data Using Transformation-Based Gaussian Mixture Models}, 
      author={Luca Scrucca},
      year={2025},
      eprint={2412.13572},
      archivePrefix={arXiv},
      primaryClass={stat.ME},
      url={https://arxiv.org/abs/2412.13572}, 
}
@article{DBLP:journals/corr/abs-1003-4394,
  author       = {Bob Coecke and
                  Mehrnoosh Sadrzadeh and
                  Stephen Clark},
  title        = {Mathematical Foundations for a Compositional Distributional Model
                  of Meaning},
  journal      = {CoRR},
  volume       = {abs/1003.4394},
  year         = {2010},
  url          = {http://arxiv.org/abs/1003.4394},
  eprinttype    = {arXiv},
  eprint       = {1003.4394},
  timestamp    = {Mon, 13 Aug 2018 16:46:35 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1003-4394.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{ZADEH1965338,
    title = {Fuzzy sets},
    journal = {Information and Control},
    volume = {8},
    number = {3},
    pages = {338-353},
    year = {1965},
    issn = {0019-9958},
    doi = {https://doi.org/10.1016/S0019-9958(65)90241-X},
    url = {https://www.sciencedirect.com/science/article/pii/S001999586590241X},
    author = {L.A. Zadeh},
    abstract = {A fuzzy set is a class of objects with a continuum of grades of membership. Such a set is characterized by a membership (characteristic) function which assigns to each object a grade of membership ranging between zero and one. The notions of inclusion, union, intersection, complement, relation, convexity, etc., are extended to such sets, and various properties of these notions in the context of fuzzy sets are established. In particular, a separation theorem for convex fuzzy sets is proved without requiring that the fuzzy sets be disjoint.}
}
@misc{zhurov2025fuzzyontologyembeddingsvisual,
      title={Fuzzy Ontology Embeddings and Visual Query Building for Ontology Exploration}, 
      author={Vladimir Zhurov and John Kausch and Kamran Sedig and Mostafa Milani},
      year={2025},
      eprint={2508.08128},
      archivePrefix={arXiv},
      primaryClass={cs.HC},
      url={https://arxiv.org/abs/2508.08128}, 
}
@article{article,
    author = {Okal, Benard and Miruka, Frida},
    year = {2016},
    month = {06},
    pages = {62-72},
    title = {Application of Set Theory Formulas in the Presentation of Lexical Meronymy},
    volume = {1},
    journal = {Saudi Journal of Humanities and Social Sciences},
    doi = {10.21276/sjhss.2016.1.2.5}
}
@misc{https://doi.org/10.5281/zenodo.17154580,
  doi = {10.5281/ZENODO.17154580},
  url = {https://zenodo.org/doi/10.5281/zenodo.17154580},
  author = {Fabiano, Nicola},
  title = {Quantum Metric Spaces: Replacing Fuzzy Metrics with the Hilbert Space  Structure of Quantum States},
  publisher = {Zenodo},
  year = {2025},
  copyright = {Creative Commons Attribution 4.0 International}
}
@misc{eisinger2025quantummethodsmanagingambiguity,
      title={Quantum Methods for Managing Ambiguity in Natural Language Processing}, 
      author={Jurek Eisinger and Ward Gauderis and Lin de Huybrecht and Geraint A. Wiggins},
      year={2025},
      eprint={2504.00040},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2504.00040}, 
}
@INPROCEEDINGS {9996813,
        author = { Alexander, Aaranya and Widdows, Dominic },
        booktitle = { 2022 IEEE/ACM 7th Symposium on Edge Computing (SEC) },
        title = {{ Quantum Text Encoding for Classification Tasks }},
        year = {2022},
        volume = {},
        ISSN = {},
        pages = {355-361},
        abstract = { This paper explores text classification on quantum computers. Previous results have achieved perfect accuracy on an artificial dataset of 100 short sentences, but at the unscalable cost of using a qubit for each word. This paper demonstrates that an amplitude encoded feature map combined with a quantum support vector machine can achieve 62% average accuracy predicting sentiment using a dataset of 50 actual movie reviews. This is still small, but considerably larger than previously-reported results in quantum NLP. },
        keywords = {Support vector machines;Computers;Costs;Text categorization;Qubit;Motion pictures;Encoding},
        doi = {10.1109/SEC54971.2022.00052},
        url = {https://doi.ieeecomputersociety.org/10.1109/SEC54971.2022.00052},
        publisher = {IEEE Computer Society},
        address = {Los Alamitos, CA, USA},
        month =Dec
}
@inproceedings{10.5555/3045118.3045221,
  author = {Kusner, Matt J. and Sun, Yu and Kolkin, Nicholas I. and Weinberger, Kilian Q.},
  title = {From word embeddings to document distances},
  year = {2015},
  publisher = {JMLR.org},
  abstract = {We present the Word Mover's Distance (WMD), a novel distance function between text documents. Our work is based on recent results in word embeddings that learn semantically meaningful representations for words from local cooccurrences in sentences. The WMD distance measures the dissimilarity between two text documents as the minimum amount of distance that the embedded words of one document need to "travel" to reach the embedded words of another document. We show that this distance metric can be cast as an instance of the Earth Mover's Distance, a well studied transportation problem for which several highly efficient solvers have been developed. Our metric has no hyperparameters and is straight-forward to implement. Further, we demonstrate on eight real world document classification data sets, in comparison with seven state-of-the-art baselines, that the WMD metric leads to unprecedented low k-nearest neighbor document classification error rates.},
  booktitle = {Proceedings of the 32nd International Conference on International Conference on Machine Learning - Volume 37},
  pages = {957–966},
  numpages = {10},
  location = {Lille, France},
  series = {ICML'15}
}
@misc{cazelles2020wassersteinfourierdistancestationarytime,
      title={The Wasserstein-Fourier Distance for Stationary Time Series}, 
      author={Elsa Cazelles and Arnaud Robert and Felipe Tobar},
      year={2020},
      eprint={1912.05509},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1912.05509}, 
}
@misc{wang2020minilmdeepselfattentiondistillation,
      title={MiniLM: Deep Self-Attention Distillation for Task-Agnostic Compression of Pre-Trained Transformers}, 
      author={Wenhui Wang and Furu Wei and Li Dong and Hangbo Bao and Nan Yang and Ming Zhou},
      year={2020},
      eprint={2002.10957},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2002.10957}, 
}

@article{bagnato_finite_2013,
	title = {Finite mixtures of unimodal beta and gamma densities and the \$\$k\$\$-bumps algorithm},
	volume = {28},
	issn = {1613-9658},
	url = {https://doi.org/10.1007/s00180-012-0367-4},
	doi = {10.1007/s00180-012-0367-4},
	abstract = {This paper addresses the problem of estimating a density, with either a compact support or a support bounded at only one end, exploiting a general and natural form of a finite mixture of distributions. Due to the importance of the concept of multimodality in the mixture framework, unimodal beta and gamma densities are used as mixture components, leading to a flexible modeling approach. Accordingly, a mode-based parameterization of the components is provided. A partitional clustering method, named \$\$k\$\$-bumps, is also proposed; it is used as an ad hoc initialization strategy in the EM algorithm to obtain the maximum likelihood estimation of the mixture parameters. The performance of the \$\$k\$\$-bumps algorithm as an initialization tool, in comparison to other common initialization strategies, is evaluated through some simulation experiments. Finally, two real applications are presented.},
	number = {4},
	journal = {Computational Statistics},
	author = {Bagnato, Luca and Punzo, Antonio},
	month = aug,
	year = {2013},
	pages = {1571--1597},
}

@misc{gallaugher_skewed_2020,
	title = {Skewed {Distributions} or {Transformations}? {Modelling} {Skewness} for a {Cluster} {Analysis}},
	shorttitle = {Skewed {Distributions} or {Transformations}?},
	url = {http://arxiv.org/abs/2011.09152},
	doi = {10.48550/arXiv.2011.09152},
	abstract = {Because of its mathematical tractability, the Gaussian mixture model holds a special place in the literature for clustering and classification. For all its benefits, however, the Gaussian mixture model poses problems when the data is skewed or contains outliers. Because of this, methods have been developed over the years for handling skewed data, and fall into two general categories. The first is to consider a mixture of more flexible skewed distributions, and the second is based on incorporating a transformation to near normality. Although these methods have been compared in their respective papers, there has yet to be a detailed comparison to determine when one method might be more suitable than the other. Herein, we provide a detailed comparison on many benchmarking datasets, as well as describe a novel method to assess cluster separation.},
	urldate = {2025-12-12},
	publisher = {arXiv},
	author = {Gallaugher, Michael P. B. and McNicholas, Paul D. and Melnykov, Volodymyr and Zhu, Xuwen},
	month = nov,
	year = {2020},
	note = {arXiv:2011.09152 [stat]},
	keywords = {Statistics - Applications},
	file = {Preprint PDF:C\:\\Users\\igeek\\Zotero\\storage\\FMLXWLJI\\Gallaugher et al. - 2020 - Skewed Distributions or Transformations Modelling Skewness for a Cluster Analysis.pdf:application/pdf;Snapshot:C\:\\Users\\igeek\\Zotero\\storage\\95S96NQY\\2011.html:text/html},
}

@article{zadeh_fuzzy_1965,
	title = {Fuzzy sets},
	volume = {8},
	issn = {0019-9958},
	url = {https://www.sciencedirect.com/science/article/pii/S001999586590241X},
	doi = {https://doi.org/10.1016/S0019-9958(65)90241-X},
	abstract = {A fuzzy set is a class of objects with a continuum of grades of membership. Such a set is characterized by a membership (characteristic) function which assigns to each object a grade of membership ranging between zero and one. The notions of inclusion, union, intersection, complement, relation, convexity, etc., are extended to such sets, and various properties of these notions in the context of fuzzy sets are established. In particular, a separation theorem for convex fuzzy sets is proved without requiring that the fuzzy sets be disjoint.},
	number = {3},
	journal = {Information and Control},
	author = {Zadeh, L. A.},
	year = {1965},
	pages = {338--353},
}
