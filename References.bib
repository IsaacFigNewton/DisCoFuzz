
@article{press_train_2021,
	title = {Train {Short}, {Test} {Long}: {Attention} with {Linear} {Biases} {Enables} {Input} {Length} {Extrapolation}},
	volume = {abs/2108.12409},
	url = {https://arxiv.org/abs/2108.12409},
	journal = {CoRR},
	author = {Press, Ofir and Smith, Noah A. and Lewis, Mike},
	year = {2021},
	note = {arXiv: 2108.12409},
}

@misc{tai_improved_2015,
	title = {Improved {Semantic} {Representations} {From} {Tree}-{Structured} {Long} {Short}-{Term} {Memory} {Networks}},
	url = {https://arxiv.org/abs/1503.00075},
	author = {Tai, Kai Sheng and Socher, Richard and Manning, Christopher D.},
	year = {2015},
	note = {\_eprint: 1503.00075},
}

@inproceedings{socher_recursive_2013,
	address = {Seattle, Washington, USA},
	title = {Recursive {Deep} {Models} for {Semantic} {Compositionality} {Over} a {Sentiment} {Treebank}},
	url = {https://aclanthology.org/D13-1170/},
	booktitle = {Proceedings of the 2013 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Socher, Richard and Perelygin, Alex and Wu, Jean and Chuang, Jason and Manning, Christopher D. and Ng, Andrew and Potts, Christopher},
	editor = {Yarowsky, David and Baldwin, Timothy and Korhonen, Anna and Livescu, Karen and Bethard, Steven},
	month = oct,
	year = {2013},
	pages = {1631--1642},
}

@article{gangemi_semantic_2017,
	title = {Semantic {Web} {Machine} {Reading} with {FRED}},
	volume = {8},
	number = {6},
	journal = {Semantic Web},
	author = {Gangemi, Aldo and Presutti, Valentina and Recupero, Diego Reforgiato and Nuzzolese, Andrea Giovanni and Draicchio, Francesco and MongiovÃ¬, Misael},
	year = {2017},
	pages = {873--893},
}

@inproceedings{gangemi_py-amr2fred_2025,
	address = {Berlin, Heidelberg},
	title = {py-amr2fred: {A} {Python} {Library} for\&nbsp;{Converting} {Text} into {OWL}-{Compliant} {RDF} {KGs}},
	isbn = {978-3-031-94577-9},
	url = {https://doi.org/10.1007/978-3-031-94578-6_4},
	doi = {10.1007/978-3-031-94578-6_4},
	abstract = {This paper introduces py-amr2fred, a Python library that converts natural language text into OWL-compliant RDF Knowledge Graphs (KGs) through an advanced pipeline integrating Large Language Models, Abstract Meaning Representation (AMR) parsing and semantic enrichment. Designed for scalability and flexibility, the library addresses limitations in existing solutions and facilitates seamless integration into diverse applications. To demonstrate its effectiveness, we present MusicBO, a domain-specific KG capturing the historical, cultural, and relational aspects of musical heritage. Constructed from a multilingual corpus, MusicBO leverages the pipeline’s capabilities for text processing, AMR parsing, RDF transformation, and quality assurance via back-translation validation. The resulting graph, comprising over 531,000 triples, is publicly accessible and serves as a resource for education, research, and digital storytelling in cultural heritage. Additionally, we propose an intrinsic evaluation method for the quality assessment of the generated KGs, leveraging Open Knowledge Extraction motifs. A manually curated benchmark dataset complements this evaluation framework, providing a valuable resource for future research in text-to-KG construction. The contributions of this work underscore the potential of py-amr2fred in advancing automated, scalable, and domain-independent KG generation.},
	booktitle = {The {Semantic} {Web}: 22nd {European} {Semantic} {Web} {Conference}, {ESWC} 2025, {Portoroz}, {Slovenia}, {June} 1–5, 2025, {Proceedings}, {Part} {II}},
	publisher = {Springer-Verlag},
	author = {Gangemi, Aldo and Graciotti, Arianna and Meloni, Antonello and Nuzzolese, Andrea G. and Presutti, Valentina and Reforgiato Recupero, Diego and Russo, Alessandro},
	year = {2025},
	note = {event-place: Portoroz, Slovenia},
	keywords = {Abstract Meaning Representation, KG construction, LLMs, Provenance-aware RDF, Semantic web technologies, Text-to-RDF transformation},
	pages = {65--83},
}

@misc{hu_grag_2025,
	title = {{GRAG}: {Graph} {Retrieval}-{Augmented} {Generation}},
	url = {https://arxiv.org/abs/2405.16506},
	author = {Hu, Yuntong and Lei, Zhihan and Zhang, Zheng and Pan, Bo and Ling, Chen and Zhao, Liang},
	year = {2025},
	note = {\_eprint: 2405.16506},
}

@inproceedings{mao_alignment_2021,
	address = {Online and Punta Cana, Dominican Republic},
	title = {From {Alignment} to {Assignment}: {Frustratingly} {Simple} {Unsupervised} {Entity} {Alignment}},
	url = {https://aclanthology.org/2021.emnlp-main.226/},
	doi = {10.18653/v1/2021.emnlp-main.226},
	abstract = {Cross-lingual entity alignment (EA) aims to find the equivalent entities between crosslingual KGs (Knowledge Graphs), which is a crucial step for integrating KGs. Recently, many GNN-based EA methods are proposed and show decent performance improvements on several public datasets. However, existing GNN-based EA methods inevitably inherit poor interpretability and low efficiency from neural networks. Motivated by the isomorphic assumption of GNN-based methods, we successfully transform the cross-lingual EA problem into an assignment problem. Based on this re-definition, we propose a frustratingly Simple but Effective Unsupervised entity alignment method (SEU) without neural networks. Extensive experiments have been conducted to show that our proposed unsupervised approach even beats advanced supervised methods across all public datasets while having high efficiency, interpretability, and stability.},
	booktitle = {Proceedings of the 2021 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Mao, Xin and Wang, Wenting and Wu, Yuanbin and Lan, Man},
	editor = {Moens, Marie-Francine and Huang, Xuanjing and Specia, Lucia and Yih, Scott Wen-tau},
	month = nov,
	year = {2021},
	pages = {2843--2853},
}

@misc{tull_towards_2024,
	title = {Towards {Compositional} {Interpretability} for {XAI}},
	url = {https://arxiv.org/abs/2406.17583},
	author = {Tull, Sean and Lorenz, Robin and Clark, Stephen and Khan, Ilyas and Coecke, Bob},
	year = {2024},
	note = {\_eprint: 2406.17583},
}

@book{wittgenstein_philosophical_1953,
	address = {New York, NY, USA},
	title = {Philosophical {Investigations}},
	publisher = {Wiley-Blackwell},
	author = {Wittgenstein, Ludwig},
	editor = {Anscombe, G. E. M.},
	year = {1953},
}

@article{senel_semantic_2018,
	title = {Semantic {Structure} and {Interpretability} of {Word} {Embeddings}},
	volume = {26},
	issn = {2329-9304},
	url = {http://dx.doi.org/10.1109/TASLP.2018.2837384},
	doi = {10.1109/taslp.2018.2837384},
	number = {10},
	journal = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
	author = {Senel, Lutfi Kerem and Utlu, Ihsan and Yucesoy, Veysel and Koc, Aykut and Cukur, Tolga},
	month = oct,
	year = {2018},
	note = {Publisher: Institute of Electrical and Electronics Engineers (IEEE)},
	pages = {1769--1779},
}

@misc{mikolov_efficient_2013,
	title = {Efficient {Estimation} of {Word} {Representations} in {Vector} {Space}},
	url = {https://arxiv.org/abs/1301.3781},
	author = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
	year = {2013},
	note = {\_eprint: 1301.3781},
}

@article{budanitsky_evaluating_2006,
	title = {Evaluating {WordNet}-based {Measures} of {Lexical} {Semantic} {Relatedness}},
	volume = {32},
	issn = {0891-2017},
	url = {https://doi.org/10.1162/coli.2006.32.1.13},
	doi = {10.1162/coli.2006.32.1.13},
	abstract = {The quantification of lexical semantic relatedness has many applications in NLP, and many different measures have been proposed. We evaluate five of these measures, all of which use WordNet as their central resource, by comparing their performance in detecting and correcting real-word spelling errors. An information-content-based measure proposed by Jiang and Conrath is found superior to those proposed by Hirst and St-Onge, Leacock and Chodorow, Lin, and Resnik. In addition, we explain why distributional similarity is not an adequate proxy for lexical semantic relatedness.},
	number = {1},
	journal = {Computational Linguistics},
	author = {Budanitsky, Alexander and Hirst, Graeme},
	month = mar,
	year = {2006},
	note = {\_eprint: https://direct.mit.edu/coli/article-pdf/32/1/13/1798246/coli.2006.32.1.13.pdf},
	pages = {13--47},
}

@misc{zhou_trustworthiness_2024,
	title = {Trustworthiness in {Retrieval}-{Augmented} {Generation} {Systems}: {A} {Survey}},
	url = {https://arxiv.org/abs/2409.10102},
	author = {Zhou, Yujia and Liu, Yan and Li, Xiaoxi and Jin, Jiajie and Qian, Hongjin and Liu, Zheng and Li, Chaozhuo and Dou, Zhicheng and Ho, Tsung-Yi and Yu, Philip S.},
	year = {2024},
	note = {\_eprint: 2409.10102},
}

@inproceedings{liu_discourse_2018,
	address = {Melbourne, Australia},
	title = {Discourse {Representation} {Structure} {Parsing}},
	url = {https://aclanthology.org/P18-1040/},
	doi = {10.18653/v1/P18-1040},
	abstract = {We introduce an open-domain neural semantic parser which generates formal meaning representations in the style of Discourse Representation Theory (DRT; Kamp and Reyle 1993). We propose a method which transforms Discourse Representation Structures (DRSs) to trees and develop a structure-aware model which decomposes the decoding process into three stages: basic DRS structure prediction, condition prediction (i.e., predicates and relations), and referent prediction (i.e., variables). Experimental results on the Groningen Meaning Bank (GMB) show that our model outperforms competitive baselines by a wide margin.},
	booktitle = {Proceedings of the 56th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Liu, Jiangming and Cohen, Shay B. and Lapata, Mirella},
	editor = {Gurevych, Iryna and Miyao, Yusuke},
	month = jul,
	year = {2018},
	pages = {429--439},
}

@inproceedings{kartsaklis_unified_2012,
	address = {Mumbai, India},
	title = {A {Unified} {Sentence} {Space} for {Categorical} {Distributional}-{Compositional} {Semantics}: {Theory} and {Experiments}},
	url = {https://aclanthology.org/C12-2054/},
	booktitle = {Proceedings of {COLING} 2012: {Posters}},
	publisher = {The COLING 2012 Organizing Committee},
	author = {Kartsaklis, Dimitri and Sadrzadeh, Mehrnoosh and Pulman, Stephen},
	editor = {Kay, Martin and Boitet, Christian},
	month = dec,
	year = {2012},
	pages = {549--558},
}

@misc{scrucca_model-based_2025,
	title = {A {Model}-{Based} {Clustering} {Approach} for {Bounded} {Data} {Using} {Transformation}-{Based} {Gaussian} {Mixture} {Models}},
	url = {https://arxiv.org/abs/2412.13572},
	author = {Scrucca, Luca},
	year = {2025},
	note = {\_eprint: 2412.13572},
}

@article{coecke_mathematical_2010,
	title = {Mathematical {Foundations} for a {Compositional} {Distributional} {Model} of {Meaning}},
	volume = {abs/1003.4394},
	url = {http://arxiv.org/abs/1003.4394},
	journal = {CoRR},
	author = {Coecke, Bob and Sadrzadeh, Mehrnoosh and Clark, Stephen},
	year = {2010},
	note = {arXiv: 1003.4394},
}

@article{zadeh_fuzzy_1965,
	title = {Fuzzy sets},
	volume = {8},
	issn = {0019-9958},
	url = {https://www.sciencedirect.com/science/article/pii/S001999586590241X},
	doi = {https://doi.org/10.1016/S0019-9958(65)90241-X},
	abstract = {A fuzzy set is a class of objects with a continuum of grades of membership. Such a set is characterized by a membership (characteristic) function which assigns to each object a grade of membership ranging between zero and one. The notions of inclusion, union, intersection, complement, relation, convexity, etc., are extended to such sets, and various properties of these notions in the context of fuzzy sets are established. In particular, a separation theorem for convex fuzzy sets is proved without requiring that the fuzzy sets be disjoint.},
	number = {3},
	journal = {Information and Control},
	author = {Zadeh, L. A.},
	year = {1965},
	pages = {338--353},
}

@misc{zhurov_fuzzy_2025,
	title = {Fuzzy {Ontology} {Embeddings} and {Visual} {Query} {Building} for {Ontology} {Exploration}},
	url = {https://arxiv.org/abs/2508.08128},
	author = {Zhurov, Vladimir and Kausch, John and Sedig, Kamran and Milani, Mostafa},
	year = {2025},
	note = {\_eprint: 2508.08128},
}

@article{okal_application_2016,
	title = {Application of {Set} {Theory} {Formulas} in the {Presentation} of {Lexical} {Meronymy}},
	volume = {1},
	doi = {10.21276/sjhss.2016.1.2.5},
	journal = {Saudi Journal of Humanities and Social Sciences},
	author = {Okal, Benard and Miruka, Frida},
	month = jun,
	year = {2016},
	pages = {62--72},
}

@misc{fabiano_quantum_2025,
	title = {Quantum {Metric} {Spaces}: {Replacing} {Fuzzy} {Metrics} with the {Hilbert} {Space} {Structure} of {Quantum} {States}},
	copyright = {Creative Commons Attribution 4.0 International},
	url = {https://zenodo.org/doi/10.5281/zenodo.17154580},
	publisher = {Zenodo},
	author = {Fabiano, Nicola},
	year = {2025},
	doi = {10.5281/ZENODO.17154580},
}

@misc{eisinger_quantum_2025,
	title = {Quantum {Methods} for {Managing} {Ambiguity} in {Natural} {Language} {Processing}},
	url = {https://arxiv.org/abs/2504.00040},
	author = {Eisinger, Jurek and Gauderis, Ward and Huybrecht, Lin de and Wiggins, Geraint A.},
	year = {2025},
	note = {\_eprint: 2504.00040},
}

@inproceedings{alexander_quantum_2022,
	address = {Los Alamitos, CA, USA},
	title = {Quantum {Text} {Encoding} for {Classification} {Tasks}},
	url = {https://doi.ieeecomputersociety.org/10.1109/SEC54971.2022.00052},
	doi = {10.1109/SEC54971.2022.00052},
	abstract = {This paper explores text classification on quantum computers. Previous results have achieved perfect accuracy on an artificial dataset of 100 short sentences, but at the unscalable cost of using a qubit for each word. This paper demonstrates that an amplitude encoded feature map combined with a quantum support vector machine can achieve 62\% average accuracy predicting sentiment using a dataset of 50 actual movie reviews. This is still small, but considerably larger than previously-reported results in quantum NLP.},
	booktitle = {2022 {IEEE}/{ACM} 7th {Symposium} on {Edge} {Computing} ({SEC})},
	publisher = {IEEE Computer Society},
	author = {Alexander, Aaranya and Widdows, Dominic},
	month = dec,
	year = {2022},
	keywords = {Computers, Costs, Encoding, Motion pictures, Qubit, Support vector machines, Text categorization},
	pages = {355--361},
}

@inproceedings{kusner_word_2015,
	address = {Lille, France},
	series = {{ICML}'15},
	title = {From word embeddings to document distances},
	abstract = {We present the Word Mover's Distance (WMD), a novel distance function between text documents. Our work is based on recent results in word embeddings that learn semantically meaningful representations for words from local cooccurrences in sentences. The WMD distance measures the dissimilarity between two text documents as the minimum amount of distance that the embedded words of one document need to "travel" to reach the embedded words of another document. We show that this distance metric can be cast as an instance of the Earth Mover's Distance, a well studied transportation problem for which several highly efficient solvers have been developed. Our metric has no hyperparameters and is straight-forward to implement. Further, we demonstrate on eight real world document classification data sets, in comparison with seven state-of-the-art baselines, that the WMD metric leads to unprecedented low k-nearest neighbor document classification error rates.},
	booktitle = {Proceedings of the 32nd {International} {Conference} on {International} {Conference} on {Machine} {Learning} - {Volume} 37},
	publisher = {JMLR.org},
	author = {Kusner, Matt J. and Sun, Yu and Kolkin, Nicholas I. and Weinberger, Kilian Q.},
	year = {2015},
	pages = {957--966},
}

@misc{cazelles_wasserstein-fourier_2020,
	title = {The {Wasserstein}-{Fourier} {Distance} for {Stationary} {Time} {Series}},
	url = {https://arxiv.org/abs/1912.05509},
	author = {Cazelles, Elsa and Robert, Arnaud and Tobar, Felipe},
	year = {2020},
	note = {\_eprint: 1912.05509},
}

@misc{wang_minilm_2020,
	title = {{MiniLM}: {Deep} {Self}-{Attention} {Distillation} for {Task}-{Agnostic} {Compression} of {Pre}-{Trained} {Transformers}},
	url = {https://arxiv.org/abs/2002.10957},
	author = {Wang, Wenhui and Wei, Furu and Dong, Li and Bao, Hangbo and Yang, Nan and Zhou, Ming},
	year = {2020},
	note = {\_eprint: 2002.10957},
}

@article{bagnato_finite_2013,
	title = {Finite mixtures of unimodal beta and gamma densities and the {\textbackslash}k{\textbackslash}-bumps algorithm},
	volume = {28},
	issn = {1613-9658},
	url = {https://doi.org/10.1007/s00180-012-0367-4},
	doi = {10.1007/s00180-012-0367-4},
	abstract = {This paper addresses the problem of estimating a density, with either a compact support or a support bounded at only one end, exploiting a general and natural form of a finite mixture of distributions. Due to the importance of the concept of multimodality in the mixture framework, unimodal beta and gamma densities are used as mixture components, leading to a flexible modeling approach. Accordingly, a mode-based parameterization of the components is provided. A partitional clustering method, named {\textbackslash}k{\textbackslash}-bumps, is also proposed; it is used as an ad hoc initialization strategy in the EM algorithm to obtain the maximum likelihood estimation of the mixture parameters. The performance of the {\textbackslash}k{\textbackslash}-bumps algorithm as an initialization tool, in comparison to other common initialization strategies, is evaluated through some simulation experiments. Finally, two real applications are presented.},
	number = {4},
	journal = {Computational Statistics},
	author = {Bagnato, Luca and Punzo, Antonio},
	month = aug,
	year = {2013},
	pages = {1571--1597},
}

@misc{gallaugher_skewed_2020,
	title = {Skewed {Distributions} or {Transformations}? {Modelling} {Skewness} for a {Cluster} {Analysis}},
	shorttitle = {Skewed {Distributions} or {Transformations}?},
	url = {http://arxiv.org/abs/2011.09152},
	abstract = {Because of its mathematical tractability, the Gaussian mixture model holds a special place in the literature for clustering and classification. For all its benefits, however, the Gaussian mixture model poses problems when the data is skewed or contains outliers. Because of this, methods have been developed over the years for handling skewed data, and fall into two general categories. The first is to consider a mixture of more flexible skewed distributions, and the second is based on incorporating a transformation to near normality. Although these methods have been compared in their respective papers, there has yet to be a detailed comparison to determine when one method might be more suitable than the other. Herein, we provide a detailed comparison on many benchmarking datasets, as well as describe a novel method to assess cluster separation.},
	urldate = {2025-12-12},
	publisher = {arXiv},
	author = {Gallaugher, Michael P. B. and McNicholas, Paul D. and Melnykov, Volodymyr and Zhu, Xuwen},
	month = nov,
	year = {2020},
	doi = {10.48550/arXiv.2011.09152},
	keywords = {Statistics - Applications},
	annote = {arXiv:2011.09152 [stat]},
	file = {Preprint PDF:C\:\\Users\\igeek\\Zotero\\storage\\U2N9QD2S\\Gallaugher et al. - 2020 - Skewed Distributions or Transformations Modelling Skewness for a Cluster Analysis.pdf:application/pdf;Snapshot:C\:\\Users\\igeek\\Zotero\\storage\\MI8RRTST\\2011.html:text/html},
}

@article{zadeh_fuzzy_1965-1,
	title = {Fuzzy sets},
	volume = {8},
	issn = {0019-9958},
	url = {https://www.sciencedirect.com/science/article/pii/S001999586590241X},
	doi = {https://doi.org/10.1016/S0019-9958(65)90241-X},
	abstract = {A fuzzy set is a class of objects with a continuum of grades of membership. Such a set is characterized by a membership (characteristic) function which assigns to each object a grade of membership ranging between zero and one. The notions of inclusion, union, intersection, complement, relation, convexity, etc., are extended to such sets, and various properties of these notions in the context of fuzzy sets are established. In particular, a separation theorem for convex fuzzy sets is proved without requiring that the fuzzy sets be disjoint.},
	number = {3},
	journal = {Information and Control},
	author = {Zadeh, L. A.},
	year = {1965},
	pages = {338--353},
}

@misc{arsanjani_evolution_nodate,
	title = {The evolution of text embeddings},
	url = {https://dr-arsanjani.medium.com/the-evolution-of-text-embeddings-75431139133d},
	author = {Arsanjani, Ali},
	annote = {n.d.},
}

@article{bernstein_could_2021,
	title = {Could a middle level be the most fundamental?},
	volume = {178},
	doi = {10.1007/s11098-020-01484-1},
	number = {4},
	journal = {Philosophical Studies},
	author = {Bernstein, Sara},
	year = {2021},
	pages = {1065--1078},
}

@article{bernstein_resisting_2024,
	title = {Resisting social categories},
	url = {https://philarchive.org/rec/BERRSC-2},
	journal = {Philosophical Studies},
	author = {Bernstein, Sara},
	year = {2024},
}

@inproceedings{bevilacqua_breaking_2020,
	title = {Breaking through the 80\% glass ceiling: {Raising} the state of the art in word sense disambiguation by incorporating knowledge graph information},
	doi = {10.18653/v1/2020.acl-main.255},
	booktitle = {Proceedings of the 58th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Bevilacqua, Michele and Navigli, Roberto},
	year = {2020},
	pages = {2854--2864},
}

@article{bolukbasi_man_2016,
	title = {Man is to computer programmer as woman is to homemaker? {Debiasing} word embeddings},
	doi = {10.48550/arXiv.1607.06520},
	journal = {arXiv},
	author = {Bolukbasi, Tolga and Chang, Kai-Wei and Zou, James and Saligrama, Venkatesh and Kalai, Adam},
	year = {2016},
}

@article{carnap_empiricism_1950,
	title = {Empiricism, semantics and ontology},
	volume = {4},
	url = {https://philpapers.org/rec/CARESA},
	number = {11},
	journal = {Revue Internationale de Philosophie},
	author = {Carnap, Rudolf},
	year = {1950},
	pages = {20--40},
}

@article{danaher_threat_2016,
	title = {The threat of algocracy: {Reality}, resistance and accommodation},
	volume = {29},
	doi = {10.1007/s13347-015-0211-1},
	number = {3},
	journal = {Philosophy \& Technology},
	author = {Danaher, John},
	year = {2016},
	pages = {245--268},
}

@book{goddard_words_2014,
	title = {Words and meanings: {Lexical} semantics across domains, languages and cultures},
	publisher = {Oxford University Press},
	author = {Goddard, Cliff and Wierzbicka, Anna},
	year = {2014},
}

@article{liu_grounding_2023,
	title = {Grounding for artificial intelligence},
	doi = {10.48550/arXiv.2312.09532},
	journal = {arXiv},
	author = {Liu, Bo},
	year = {2023},
}

@article{liu_mact_2024,
	title = {{MACT}: {Model}-agnostic cross-lingual training for discourse representation structure parsing},
	doi = {10.48550/arXiv.2406.01052},
	journal = {arXiv},
	author = {Liu, Jiangnan},
	year = {2024},
}

@inproceedings{liu_discourse_2018-1,
	title = {Discourse representation structure parsing},
	doi = {10.18653/v1/P18-1040},
	booktitle = {Proceedings of the 56th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Liu, Jiangming and Cohen, Shay B. and Lapata, Mirella},
	year = {2018},
	pages = {429--439},
}

@article{mcpheat_vector_2021,
	title = {Vector space semantics for {Lambek} calculus with soft subexponentials},
	doi = {10.48550/arXiv.2111.11331},
	journal = {arXiv},
	author = {McPheat, Lucy and Wazni, Hisham and Sadrzadeh, Mehrnoosh},
	year = {2021},
}

@inproceedings{morazzoni_def2vec_2023,
	title = {{Def2Vec}: {Extensible} word embeddings from dictionary definitions},
	url = {https://aclanthology.org/2023.icnlsp-1.21/},
	booktitle = {Proceedings of the 5th {International} {Conference} on {Natural} {Language} and {Speech} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Morazzoni, Ilaria and Poltronieri, Andrea and Gangemi, Aldo and Presutti, Valentina and Reforgiato Recupero, Diego},
	year = {2023},
	pages = {179--189},
}

@incollection{oconnor_emergent_2019,
	title = {Emergent properties},
	url = {https://plato.stanford.edu/entries/properties-emergent/},
	booktitle = {The {Stanford} {Encyclopedia} of {Philosophy} ({Winter} 2019 {Edition})},
	author = {O'Connor, Timothy},
	editor = {Zalta, Edward N.},
	year = {2019},
}

@article{oconnor_metaphysics_2005,
	title = {The metaphysics of emergence},
	volume = {39},
	url = {https://www.jstor.org/stable/3506115},
	number = {4},
	journal = {Noûs},
	author = {O'Connor, Timothy and Wong, Hong Yu},
	year = {2005},
	pages = {658--678},
}

@article{opitz_interpretable_2025,
	title = {Interpretable text embeddings and text similarity explanation: {A} primer},
	doi = {10.48550/arXiv.2502.14862},
	journal = {arXiv},
	author = {Opitz, Juri and Lindner, Sandra and Frank, Anette},
	year = {2025},
}

@article{paul_metaphysics_2012,
	title = {Metaphysics as modeling: {The} handmaiden's tale},
	volume = {160},
	doi = {10.1007/s11098-012-9906-7},
	number = {1},
	journal = {Philosophical Studies},
	author = {Paul, L. A.},
	year = {2012},
	pages = {1--29},
}

@article{peng_graph_2024,
	title = {Graph retrieval-augmented generation: {A} survey},
	doi = {10.48550/arXiv.2408.08921},
	journal = {arXiv},
	author = {Peng, Baolin and Chen, Chen and Feng, Ling and Xu, Jing and Pei, Jian and Luo, Min and Han, Xianpei and Zhao, Wayne Xin},
	year = {2024},
}

@incollection{rudnicki_best_2016,
	title = {Best practices of ontology development},
	url = {https://philarchive.org/rec/RUDBPO},
	booktitle = {{CUBRC} {Ontology} {Works}},
	author = {Rudnicki, Rafael and Smith, Barry and Malyuta, Timur and Mandrick, William},
	year = {2016},
	pages = {68--84},
}

@inproceedings{saedi_wordnet_2018,
	title = {{WordNet} embeddings},
	doi = {10.18653/v1/W18-3016},
	booktitle = {Proceedings of the {Third} {Workshop} on {Representation} {Learning} for {NLP}},
	publisher = {Association for Computational Linguistics},
	author = {Saedi, Chaya and Branco, António and Rodrigues, João António and Silva, João},
	year = {2018},
	pages = {122--131},
}

@article{sanmartin_kg-rag_2024,
	title = {{KG}-{RAG}: {Bridging} the gap between knowledge and creativity},
	doi = {10.48550/arXiv.2405.12035},
	journal = {arXiv},
	author = {Sanmartin, Daniel},
	year = {2024},
}

@incollection{schaffer_what_2009,
	title = {On what grounds what},
	url = {https://philpapers.org/rec/SCHOWG},
	booktitle = {Metametaphysics: {New} essays on the foundations of ontology},
	publisher = {Oxford University Press},
	author = {Schaffer, Jonathan},
	editor = {Chalmers, David and Manley, David and Wasserman, Ryan},
	year = {2009},
	pages = {347--383},
}

@inproceedings{shih_sense_2014,
	title = {Sense decomposition from {E}-{HowNet} for word similarity measurement},
	doi = {10.1109/IRI.2014.7051946},
	booktitle = {Proceedings of the 2014 {IEEE} 15th {International} {Conference} on {Information} {Reuse} and {Integration}},
	publisher = {IEEE},
	author = {Shih, Chih-Wei and Hsieh, Yi-Lin and Hsu, Wen-Lian},
	year = {2014},
	pages = {613--618},
}

@article{van_noord_exploring_2018,
	title = {Exploring neural methods for parsing discourse representation structures},
	volume = {6},
	doi = {10.1162/tacl_a_00241},
	journal = {Transactions of the Association for Computational Linguistics},
	author = {van Noord, Rik and Abzianidze, Lasha and Toral, Antonio and Bos, Johan},
	year = {2018},
	pages = {619--633},
}

@inproceedings{williams_grounding_1997,
	title = {A grounding framework},
	url = {https://www.researchgate.net/publication/220660856_A_grounding_framework},
	booktitle = {{AAAI} {Technical} {Report} {WS}-97-03},
	publisher = {AAAI Press},
	author = {Williams, Mary-Anne and Katz, Sam and Lakemeyer, Gerhard and Perlis, Donald},
	year = {1997},
}

@article{zhou_trustworthiness_2024-1,
	title = {Trustworthiness in retrieval-augmented generation systems: {A} survey},
	doi = {10.48550/arXiv.2409.10102},
	journal = {arXiv},
	author = {Zhou, Yuxuan and Zhao, Jing and Xie, Jialu and Wu, Jing and Li, Zihan and Jiang, Meng},
	year = {2024},
}
