
@article{press_train_2021,
	title = {Train {Short}, {Test} {Long}: {Attention} with {Linear} {Biases} {Enables} {Input} {Length} {Extrapolation}},
	volume = {abs/2108.12409},
	url = {https://arxiv.org/abs/2108.12409},
	journal = {CoRR},
	author = {Press, Ofir and Smith, Noah A. and Lewis, Mike},
	year = {2021},
	note = {arXiv: 2108.12409},
}

@misc{tai_improved_2015,
	title = {Improved {Semantic} {Representations} {From} {Tree}-{Structured} {Long} {Short}-{Term} {Memory} {Networks}},
	url = {https://arxiv.org/abs/1503.00075},
	author = {Tai, Kai Sheng and Socher, Richard and Manning, Christopher D.},
	year = {2015},
	note = {\_eprint: 1503.00075},
}

@inproceedings{socher_recursive_2013,
	address = {Seattle, Washington, USA},
	title = {Recursive {Deep} {Models} for {Semantic} {Compositionality} {Over} a {Sentiment} {Treebank}},
	url = {https://aclanthology.org/D13-1170/},
	booktitle = {Proceedings of the 2013 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Socher, Richard and Perelygin, Alex and Wu, Jean and Chuang, Jason and Manning, Christopher D. and Ng, Andrew and Potts, Christopher},
	editor = {Yarowsky, David and Baldwin, Timothy and Korhonen, Anna and Livescu, Karen and Bethard, Steven},
	month = oct,
	year = {2013},
	pages = {1631--1642},
}

@article{gangemi_semantic_2017,
	title = {Semantic {Web} {Machine} {Reading} with {FRED}},
	volume = {8},
	number = {6},
	journal = {Semantic Web},
	author = {Gangemi, Aldo and Presutti, Valentina and Recupero, Diego Reforgiato and Nuzzolese, Andrea Giovanni and Draicchio, Francesco and MongiovÃ¬, Misael},
	year = {2017},
	pages = {873--893},
}

@inproceedings{gangemi_py-amr2fred_2025,
	address = {Berlin, Heidelberg},
	title = {py-amr2fred: {A} {Python} {Library} for\&nbsp;{Converting} {Text} into {OWL}-{Compliant} {RDF} {KGs}},
	isbn = {978-3-031-94577-9},
	url = {https://doi.org/10.1007/978-3-031-94578-6_4},
	doi = {10.1007/978-3-031-94578-6_4},
	abstract = {This paper introduces py-amr2fred, a Python library that converts natural language text into OWL-compliant RDF Knowledge Graphs (KGs) through an advanced pipeline integrating Large Language Models, Abstract Meaning Representation (AMR) parsing and semantic enrichment. Designed for scalability and flexibility, the library addresses limitations in existing solutions and facilitates seamless integration into diverse applications. To demonstrate its effectiveness, we present MusicBO, a domain-specific KG capturing the historical, cultural, and relational aspects of musical heritage. Constructed from a multilingual corpus, MusicBO leverages the pipeline’s capabilities for text processing, AMR parsing, RDF transformation, and quality assurance via back-translation validation. The resulting graph, comprising over 531,000 triples, is publicly accessible and serves as a resource for education, research, and digital storytelling in cultural heritage. Additionally, we propose an intrinsic evaluation method for the quality assessment of the generated KGs, leveraging Open Knowledge Extraction motifs. A manually curated benchmark dataset complements this evaluation framework, providing a valuable resource for future research in text-to-KG construction. The contributions of this work underscore the potential of py-amr2fred in advancing automated, scalable, and domain-independent KG generation.},
	booktitle = {The {Semantic} {Web}: 22nd {European} {Semantic} {Web} {Conference}, {ESWC} 2025, {Portoroz}, {Slovenia}, {June} 1–5, 2025, {Proceedings}, {Part} {II}},
	publisher = {Springer-Verlag},
	author = {Gangemi, Aldo and Graciotti, Arianna and Meloni, Antonello and Nuzzolese, Andrea G. and Presutti, Valentina and Reforgiato Recupero, Diego and Russo, Alessandro},
	year = {2025},
	note = {event-place: Portoroz, Slovenia},
	keywords = {Abstract Meaning Representation, KG construction, LLMs, Provenance-aware RDF, Semantic web technologies, Text-to-RDF transformation},
	pages = {65--83},
}

@misc{hu_grag_2025,
	title = {{GRAG}: {Graph} {Retrieval}-{Augmented} {Generation}},
	url = {https://arxiv.org/abs/2405.16506},
	author = {Hu, Yuntong and Lei, Zhihan and Zhang, Zheng and Pan, Bo and Ling, Chen and Zhao, Liang},
	year = {2025},
	note = {\_eprint: 2405.16506},
}

@inproceedings{mao_alignment_2021,
	address = {Online and Punta Cana, Dominican Republic},
	title = {From {Alignment} to {Assignment}: {Frustratingly} {Simple} {Unsupervised} {Entity} {Alignment}},
	url = {https://aclanthology.org/2021.emnlp-main.226/},
	doi = {10.18653/v1/2021.emnlp-main.226},
	abstract = {Cross-lingual entity alignment (EA) aims to find the equivalent entities between crosslingual KGs (Knowledge Graphs), which is a crucial step for integrating KGs. Recently, many GNN-based EA methods are proposed and show decent performance improvements on several public datasets. However, existing GNN-based EA methods inevitably inherit poor interpretability and low efficiency from neural networks. Motivated by the isomorphic assumption of GNN-based methods, we successfully transform the cross-lingual EA problem into an assignment problem. Based on this re-definition, we propose a frustratingly Simple but Effective Unsupervised entity alignment method (SEU) without neural networks. Extensive experiments have been conducted to show that our proposed unsupervised approach even beats advanced supervised methods across all public datasets while having high efficiency, interpretability, and stability.},
	booktitle = {Proceedings of the 2021 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Mao, Xin and Wang, Wenting and Wu, Yuanbin and Lan, Man},
	editor = {Moens, Marie-Francine and Huang, Xuanjing and Specia, Lucia and Yih, Scott Wen-tau},
	month = nov,
	year = {2021},
	pages = {2843--2853},
}

@misc{tull_towards_2024,
	title = {Towards {Compositional} {Interpretability} for {XAI}},
	url = {https://arxiv.org/abs/2406.17583},
	author = {Tull, Sean and Lorenz, Robin and Clark, Stephen and Khan, Ilyas and Coecke, Bob},
	year = {2024},
	note = {\_eprint: 2406.17583},
}

@book{wittgenstein_philosophical_1953,
	address = {New York, NY, USA},
	title = {Philosophical {Investigations}},
	publisher = {Wiley-Blackwell},
	author = {Wittgenstein, Ludwig},
	editor = {Anscombe, G. E. M.},
	year = {1953},
}

@article{senel_semantic_2018,
	title = {Semantic {Structure} and {Interpretability} of {Word} {Embeddings}},
	volume = {26},
	issn = {2329-9304},
	url = {http://dx.doi.org/10.1109/TASLP.2018.2837384},
	doi = {10.1109/taslp.2018.2837384},
	number = {10},
	journal = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
	author = {Senel, Lutfi Kerem and Utlu, Ihsan and Yucesoy, Veysel and Koc, Aykut and Cukur, Tolga},
	month = oct,
	year = {2018},
	note = {Publisher: Institute of Electrical and Electronics Engineers (IEEE)},
	pages = {1769--1779},
}

@misc{mikolov_efficient_2013,
	title = {Efficient {Estimation} of {Word} {Representations} in {Vector} {Space}},
	url = {https://arxiv.org/abs/1301.3781},
	author = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
	year = {2013},
	note = {\_eprint: 1301.3781},
}

@article{budanitsky_evaluating_2006,
	title = {Evaluating {WordNet}-based {Measures} of {Lexical} {Semantic} {Relatedness}},
	volume = {32},
	issn = {0891-2017},
	url = {https://doi.org/10.1162/coli.2006.32.1.13},
	doi = {10.1162/coli.2006.32.1.13},
	abstract = {The quantification of lexical semantic relatedness has many applications in NLP, and many different measures have been proposed. We evaluate five of these measures, all of which use WordNet as their central resource, by comparing their performance in detecting and correcting real-word spelling errors. An information-content-based measure proposed by Jiang and Conrath is found superior to those proposed by Hirst and St-Onge, Leacock and Chodorow, Lin, and Resnik. In addition, we explain why distributional similarity is not an adequate proxy for lexical semantic relatedness.},
	number = {1},
	journal = {Computational Linguistics},
	author = {Budanitsky, Alexander and Hirst, Graeme},
	month = mar,
	year = {2006},
	note = {\_eprint: https://direct.mit.edu/coli/article-pdf/32/1/13/1798246/coli.2006.32.1.13.pdf},
	pages = {13--47},
}

@inproceedings{kartsaklis_unified_2012,
	address = {Mumbai, India},
	title = {A {Unified} {Sentence} {Space} for {Categorical} {Distributional}-{Compositional} {Semantics}: {Theory} and {Experiments}},
	url = {https://aclanthology.org/C12-2054/},
	booktitle = {Proceedings of {COLING} 2012: {Posters}},
	publisher = {The COLING 2012 Organizing Committee},
	author = {Kartsaklis, Dimitri and Sadrzadeh, Mehrnoosh and Pulman, Stephen},
	editor = {Kay, Martin and Boitet, Christian},
	month = dec,
	year = {2012},
	pages = {549--558},
}

@misc{scrucca_model-based_2025,
	title = {A {Model}-{Based} {Clustering} {Approach} for {Bounded} {Data} {Using} {Transformation}-{Based} {Gaussian} {Mixture} {Models}},
	url = {https://arxiv.org/abs/2412.13572},
	author = {Scrucca, Luca},
	year = {2025},
	note = {\_eprint: 2412.13572},
}

@article{coecke_mathematical_2010,
	title = {Mathematical {Foundations} for a {Compositional} {Distributional} {Model} of {Meaning}},
	volume = {abs/1003.4394},
	url = {http://arxiv.org/abs/1003.4394},
	journal = {CoRR},
	author = {Coecke, Bob and Sadrzadeh, Mehrnoosh and Clark, Stephen},
	year = {2010},
	note = {arXiv: 1003.4394},
}

@article{zadeh_fuzzy_1965,
	title = {Fuzzy sets},
	volume = {8},
	issn = {0019-9958},
	url = {https://www.sciencedirect.com/science/article/pii/S001999586590241X},
	doi = {https://doi.org/10.1016/S0019-9958(65)90241-X},
	abstract = {A fuzzy set is a class of objects with a continuum of grades of membership. Such a set is characterized by a membership (characteristic) function which assigns to each object a grade of membership ranging between zero and one. The notions of inclusion, union, intersection, complement, relation, convexity, etc., are extended to such sets, and various properties of these notions in the context of fuzzy sets are established. In particular, a separation theorem for convex fuzzy sets is proved without requiring that the fuzzy sets be disjoint.},
	number = {3},
	journal = {Information and Control},
	author = {Zadeh, L. A.},
	year = {1965},
	pages = {338--353},
}

@misc{zhurov_fuzzy_2025,
	title = {Fuzzy {Ontology} {Embeddings} and {Visual} {Query} {Building} for {Ontology} {Exploration}},
	url = {https://arxiv.org/abs/2508.08128},
	author = {Zhurov, Vladimir and Kausch, John and Sedig, Kamran and Milani, Mostafa},
	year = {2025},
	note = {\_eprint: 2508.08128},
}

@article{okal_application_2016,
	title = {Application of {Set} {Theory} {Formulas} in the {Presentation} of {Lexical} {Meronymy}},
	volume = {1},
	doi = {10.21276/sjhss.2016.1.2.5},
	journal = {Saudi Journal of Humanities and Social Sciences},
	author = {Okal, Benard and Miruka, Frida},
	month = jun,
	year = {2016},
	pages = {62--72},
}

@misc{fabiano_quantum_2025,
	title = {Quantum {Metric} {Spaces}: {Replacing} {Fuzzy} {Metrics} with the {Hilbert} {Space} {Structure} of {Quantum} {States}},
	copyright = {Creative Commons Attribution 4.0 International},
	url = {https://zenodo.org/doi/10.5281/zenodo.17154580},
	publisher = {Zenodo},
	author = {Fabiano, Nicola},
	year = {2025},
	doi = {10.5281/ZENODO.17154580},
}

@misc{eisinger_quantum_2025,
	title = {Quantum {Methods} for {Managing} {Ambiguity} in {Natural} {Language} {Processing}},
	url = {https://arxiv.org/abs/2504.00040},
	author = {Eisinger, Jurek and Gauderis, Ward and Huybrecht, Lin de and Wiggins, Geraint A.},
	year = {2025},
	note = {\_eprint: 2504.00040},
}

@inproceedings{kusner_word_2015,
	address = {Lille, France},
	series = {{ICML}'15},
	title = {From word embeddings to document distances},
	abstract = {We present the Word Mover's Distance (WMD), a novel distance function between text documents. Our work is based on recent results in word embeddings that learn semantically meaningful representations for words from local cooccurrences in sentences. The WMD distance measures the dissimilarity between two text documents as the minimum amount of distance that the embedded words of one document need to "travel" to reach the embedded words of another document. We show that this distance metric can be cast as an instance of the Earth Mover's Distance, a well studied transportation problem for which several highly efficient solvers have been developed. Our metric has no hyperparameters and is straight-forward to implement. Further, we demonstrate on eight real world document classification data sets, in comparison with seven state-of-the-art baselines, that the WMD metric leads to unprecedented low k-nearest neighbor document classification error rates.},
	booktitle = {Proceedings of the 32nd {International} {Conference} on {International} {Conference} on {Machine} {Learning} - {Volume} 37},
	publisher = {JMLR.org},
	author = {Kusner, Matt J. and Sun, Yu and Kolkin, Nicholas I. and Weinberger, Kilian Q.},
	year = {2015},
	pages = {957--966},
}

@misc{wang_minilm_2020,
	title = {{MiniLM}: {Deep} {Self}-{Attention} {Distillation} for {Task}-{Agnostic} {Compression} of {Pre}-{Trained} {Transformers}},
	url = {https://arxiv.org/abs/2002.10957},
	author = {Wang, Wenhui and Wei, Furu and Dong, Li and Bao, Hangbo and Yang, Nan and Zhou, Ming},
	year = {2020},
	note = {\_eprint: 2002.10957},
}

@article{bagnato_finite_2013,
	title = {Finite mixtures of unimodal beta and gamma densities and the {\textbackslash}k{\textbackslash}-bumps algorithm},
	volume = {28},
	issn = {1613-9658},
	url = {https://doi.org/10.1007/s00180-012-0367-4},
	doi = {10.1007/s00180-012-0367-4},
	abstract = {This paper addresses the problem of estimating a density, with either a compact support or a support bounded at only one end, exploiting a general and natural form of a finite mixture of distributions. Due to the importance of the concept of multimodality in the mixture framework, unimodal beta and gamma densities are used as mixture components, leading to a flexible modeling approach. Accordingly, a mode-based parameterization of the components is provided. A partitional clustering method, named {\textbackslash}k{\textbackslash}-bumps, is also proposed; it is used as an ad hoc initialization strategy in the EM algorithm to obtain the maximum likelihood estimation of the mixture parameters. The performance of the {\textbackslash}k{\textbackslash}-bumps algorithm as an initialization tool, in comparison to other common initialization strategies, is evaluated through some simulation experiments. Finally, two real applications are presented.},
	number = {4},
	journal = {Computational Statistics},
	author = {Bagnato, Luca and Punzo, Antonio},
	month = aug,
	year = {2013},
	pages = {1571--1597},
}

@misc{gallaugher_skewed_2020,
	title = {Skewed {Distributions} or {Transformations}? {Modelling} {Skewness} for a {Cluster} {Analysis}},
	shorttitle = {Skewed {Distributions} or {Transformations}?},
	url = {http://arxiv.org/abs/2011.09152},
	abstract = {Because of its mathematical tractability, the Gaussian mixture model holds a special place in the literature for clustering and classification. For all its benefits, however, the Gaussian mixture model poses problems when the data is skewed or contains outliers. Because of this, methods have been developed over the years for handling skewed data, and fall into two general categories. The first is to consider a mixture of more flexible skewed distributions, and the second is based on incorporating a transformation to near normality. Although these methods have been compared in their respective papers, there has yet to be a detailed comparison to determine when one method might be more suitable than the other. Herein, we provide a detailed comparison on many benchmarking datasets, as well as describe a novel method to assess cluster separation.},
	urldate = {2025-12-12},
	publisher = {arXiv},
	author = {Gallaugher, Michael P. B. and McNicholas, Paul D. and Melnykov, Volodymyr and Zhu, Xuwen},
	month = nov,
	year = {2020},
	doi = {10.48550/arXiv.2011.09152},
	keywords = {Statistics - Applications},
	annote = {arXiv:2011.09152 [stat]},
	file = {Preprint PDF:C\:\\Users\\igeek\\Zotero\\storage\\U2N9QD2S\\Gallaugher et al. - 2020 - Skewed Distributions or Transformations Modelling Skewness for a Cluster Analysis.pdf:application/pdf;Snapshot:C\:\\Users\\igeek\\Zotero\\storage\\MI8RRTST\\2011.html:text/html},
}

@misc{arsanjani_evolution_nodate,
	title = {The evolution of text embeddings},
	url = {https://dr-arsanjani.medium.com/the-evolution-of-text-embeddings-75431139133d},
	author = {Arsanjani, Ali},
	annote = {n.d.},
}

@article{bolukbasi_man_2016,
	title = {Man is to computer programmer as woman is to homemaker? {Debiasing} word embeddings},
	doi = {10.48550/arXiv.1607.06520},
	journal = {arXiv},
	author = {Bolukbasi, Tolga and Chang, Kai-Wei and Zou, James and Saligrama, Venkatesh and Kalai, Adam},
	year = {2016},
}

@inproceedings{liu_discourse_2018,
	title = {Discourse representation structure parsing},
	doi = {10.18653/v1/P18-1040},
	booktitle = {Proceedings of the 56th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Liu, Jiangming and Cohen, Shay B. and Lapata, Mirella},
	year = {2018},
	pages = {429--439},
}

@article{opitz_interpretable_2025,
	title = {Interpretable text embeddings and text similarity explanation: {A} primer},
	doi = {10.48550/arXiv.2502.14862},
	journal = {arXiv},
	author = {Opitz, Juri and Lindner, Sandra and Frank, Anette},
	year = {2025},
}

@article{peng_graph_2024,
	title = {Graph retrieval-augmented generation: {A} survey},
	doi = {10.48550/arXiv.2408.08921},
	journal = {arXiv},
	author = {Peng, Baolin and Chen, Chen and Feng, Ling and Xu, Jing and Pei, Jian and Luo, Min and Han, Xianpei and Zhao, Wayne Xin},
	year = {2024},
}

@inproceedings{saedi_wordnet_2018,
	title = {{WordNet} embeddings},
	doi = {10.18653/v1/W18-3016},
	booktitle = {Proceedings of the {Third} {Workshop} on {Representation} {Learning} for {NLP}},
	publisher = {Association for Computational Linguistics},
	author = {Saedi, Chaya and Branco, António and Rodrigues, João António and Silva, João},
	year = {2018},
	pages = {122--131},
}

@inproceedings{shih_sense_2014,
	title = {Sense decomposition from {E}-{HowNet} for word similarity measurement},
	doi = {10.1109/IRI.2014.7051946},
	booktitle = {Proceedings of the 2014 {IEEE} 15th {International} {Conference} on {Information} {Reuse} and {Integration}},
	publisher = {IEEE},
	author = {Shih, Chih-Wei and Hsieh, Yi-Lin and Hsu, Wen-Lian},
	year = {2014},
	pages = {613--618},
}

@article{van_noord_exploring_2018,
	title = {Exploring neural methods for parsing discourse representation structures},
	volume = {6},
	doi = {10.1162/tacl_a_00241},
	journal = {Transactions of the Association for Computational Linguistics},
	author = {van Noord, Rik and Abzianidze, Lasha and Toral, Antonio and Bos, Johan},
	year = {2018},
	pages = {619--633},
}

@article{zhou_trustworthiness_2024,
	title = {Trustworthiness in retrieval-augmented generation systems: {A} survey},
	doi = {10.48550/arXiv.2409.10102},
	journal = {arXiv},
	author = {Zhou, Yuxuan and Zhao, Jing and Xie, Jialu and Wu, Jing and Li, Zihan and Jiang, Meng},
	year = {2024},
}

@article{Vaswani_Shazeer_Parmar_Uszkoreit_Jones_Gomez_Kaiser_Polosukhin_2017, 
title={Attention is All you Need}, 
url={https://www.semanticscholar.org/paper/204e3073870fae3d05bcbc2f6a8e263d9b72e776}, 
author={Vaswani, Ashish and Shazeer, Noam M. and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, I.}, 
year={2017}, 
month=june 
}

@article{Shaw_Uszkoreit_Vaswani_2018, 
title={Self-Attention with Relative Position Representations}, 
url={https://aclanthology.org/N18-2074/}, 
author={Shaw, Peter and Uszkoreit, Jakob and Vaswani, Ashish}, 
year={2018}, 
month=mar 
}

@article{Doshi-Velez_Kim_2017, 
title={Towards A Rigorous Science of Interpretable Machine Learning}, 
url={https://www.semanticscholar.org/paper/5c39e37022661f81f79e481240ed9b175dec6513}, 
journal={arXiv: Machine Learning}, 
author={Doshi-Velez, F. and Kim, Been}, 
year={2017}, 
month=feb 
}

@article{Mikolov_Chen_Corrado_Dean_2013, 
title={Efficient Estimation of Word Representations in Vector Space}, 
url={https://www.semanticscholar.org/paper/f6b51c8753a871dc94ff32152c00c01e94f90f09}, 
author={Mikolov, Tomas and Chen, Kai and Corrado, G. and Dean, J.}, 
year={2013}, 
month=jan 
}

@article{Pennington_Socher_Manning_2014, 
title={GloVe: Global Vectors for Word Representation}, 
url={https://aclanthology.org/D14-1162/}, 
author={Pennington, Jeffrey and Socher, R. and Manning, Christopher D.}, 
year={2014}, 
month=sept 
}

@inproceedings{10.5555/1626481.1626503,
author = {Bos, Johan},
title = {Wide-coverage semantic analysis with Boxer},
year = {2008},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {Boxer is an open-domain software component for semantic analysis of text, based on Combinatory Categorial Grammar (CCG) and Discourse Representation Theory (DRT). Used together with the C&C tools, Boxer reaches more than 95\% coverage on newswire texts. The semantic representations produced by Boxer, known as Discourse Representation Structures (DRSs), incorporate a neo-Davidsonian representations for events, using the VerbNet inventory of thematic roles. The resulting DRSs can be translated to ordinary first-order logic formulas and be processing by standard theorem provers for first-order logic. Boxer's performance on the shared task for comparing semantic represtations was promising. It was able to produce complete DRSs for all seven texts. Manually inspecting the output revealed that: (a) the computed predicate argument structure was generally of high quality, in particular dealing with hard constructions involving control or coordination; (b) discourse structure triggered by conditionals, negation or discourse adverbs was overall correctly computed; (c) some measure and time expressions are correctly analysed, others aren't; (d) several shallow analyses are given for lexical phrases that require deep analysis; (e) bridging references and pronouns are not resolved in most cases. Boxer is distributed with the C&C tools and freely available for research purposes.},
booktitle = {Proceedings of the 2008 Conference on Semantics in Text Processing},
pages = {277–286},
numpages = {10},
location = {Venice, Italy},
series = {STEP '08}
}

@article{Kartsaklis_Fan_Yeung_Pearson_Lorenz_Toumi_Felice_Meichanetzidis_Clark_Coecke_2021, 
title={lambeq: An Efficient High-Level Python Library for Quantum NLP}, 
url={https://www.semanticscholar.org/paper/63e60bdd1c4555b4bdb82d87c0bc19ede005ab53}, 
journal={ArXiv}, 
author={Kartsaklis, Dimitri and Fan, Ian and Yeung, Richie and Pearson, A. and Lorenz, Robin and Toumi, Alexis and Felice, G. and Meichanetzidis, K. and Clark, S. and Coecke, B.}, 
year={2021}, 
month=oct 
}

@article{Tiezzi_Marra_Melacci_Maggini_2020, 
title={Deep Constraint-Based Propagation in Graph Neural Networks}, 
url={https://ieeexplore.ieee.org/document/9405452/}, 
journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
author={Tiezzi, Matteo and Marra, G. and Melacci, S. and Maggini, Marco}, 
year={2020}, 
month=may 
}

@article{Velickovic_Cucurull_Casanova_Romero_Lio’_Bengio_2017, 
title={Graph Attention Networks}, 
url={https://www.semanticscholar.org/paper/33998aff64ce51df8dee45989cdca4b6b1329ec4}, 
journal={ArXiv}, 
author={Velickovic, Petar and Cucurull, Guillem and Casanova, Arantxa and Romero, Adriana and Lio’, P. and Bengio, Yoshua}, 
year={2017}, 
month=oct 
}